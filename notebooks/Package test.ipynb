{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6bafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from droughts_modelling.data import DataFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6002e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import models,layers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from droughts_modelling.data import DataFunctions\n",
    "from droughts_modelling.window_gen import WindowGenerator\n",
    "import numpy as np\n",
    "\n",
    "class DeepLearning2():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_data = DataFunctions().light_weekly_aggregate_train()\n",
    "        self.test_data = DataFunctions().light_weekly_aggregate_test()\n",
    "        self.features = self.train_data.drop(columns=['fips_','year_','week_num_','score_max']).columns\n",
    "    \n",
    "    #Data Scaling: Train and Test\n",
    "    def robust(self):\n",
    "        train_df = self.train_data.copy()\n",
    "        test_df = self.test_data.copy()\n",
    "        for f in self.features:\n",
    "            train_median = np.median(train_df[f])\n",
    "            train_iqr = np.subtract(*np.percentile(train_df[f], [75, 25]))\n",
    "            train_df[f] = train_df[f].map(lambda x: (x-train_median)/train_iqr)\n",
    "            test_df[f] = test_df[f].map(lambda x: (x-train_median)/train_iqr)\n",
    "            \n",
    "        self.train_df_robust = train_df\n",
    "        self.test_df_robust = test_df\n",
    "    \n",
    "    #Train data preprocessing\n",
    "    def train_ohe(self):\n",
    "        self.robust()\n",
    "        df = self.train_df_robust.copy()\n",
    "        ohe = OneHotEncoder(sparse = False)\n",
    "        ohe.fit(df[['score_max']])\n",
    "        scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "        df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "        self.train_df_robust_ohe = df.drop(columns=['score_max'])\n",
    "        \n",
    "    def train_window(self):\n",
    "        self.train_ohe()\n",
    "        self.train_windowed_data = WindowGenerator(self.train_df_robust_ohe,input_width=6,label_width=6,shift=1,label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\n",
    "    \n",
    "    #Test data preprocessing\n",
    "    def test_ohe(self):\n",
    "        self.robust()\n",
    "        df = self.test_df_robust.copy()\n",
    "        ohe = OneHotEncoder(sparse = False)\n",
    "        ohe.fit(df[['score_max']])\n",
    "        scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "        df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "        self.test_df_robust_ohe = df.drop(columns=['score_max']) \n",
    "    \n",
    "    def test_window(self):\n",
    "        self.test_ohe()\n",
    "        self.test_windowed_data = WindowGenerator(self.test_df_robust_ohe,input_width=6,label_width=6,shift=1,label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\n",
    "    \n",
    "    #Model + evaluation\n",
    "    def initialize_model(self):\n",
    "        self.model = models.Sequential()\n",
    "        self.model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "        self.model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "        self.model.add(layers.Dense(20,activation='relu'))\n",
    "        self.model.add(layers.Dense(6,activation='softmax'))\n",
    "        self.model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "        \n",
    "    def train_model(self):\n",
    "        self.initialize_model()\n",
    "        self.train_window()\n",
    "        self.model.fit(self.train_windowed_data,epochs=1,batch_size=32,verbose=1)\n",
    "        \n",
    "    def evaluate_model(self):\n",
    "        self.train_model()\n",
    "        self.test_window()\n",
    "        self.model.evaluate(self.test_windowed_data,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3467940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from droughts_modelling.Updated_DL_trainer import DeepLearning2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dad73d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86150/86150 [==============================] - 1066s 12ms/step - loss: 1.2192 - accuracy: 0.5996\n",
      "10198/10198 [==============================] - 46s 4ms/step - loss: 0.8798 - accuracy: 0.7588\n"
     ]
    }
   ],
   "source": [
    "DeepLearning2().evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdabf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droughts",
   "language": "python",
   "name": "droughts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
