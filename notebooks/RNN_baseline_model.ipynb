{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 18,
   "id": "db6a4b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "804ef6f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2120/3813386978.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdroughts_modelling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],

   "execution_count": 5,
   "id": "804ef6f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],

   "source": [
    "from droughts_modelling.data import DataFunctions\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {

   "cell_type": "code",
   "execution_count": 16,
   "id": "9d5ca0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jackhooper/code/realGhostFoxx/droughts_modelling'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {

   "cell_type": "markdown",
   "id": "f1efa360",
   "metadata": {},
   "source": [
    "1. Sort out the pipeline and Keras wrapper so as to package everything up to run for train/val/test data and iterate\n",
    "2. Hook the trainings up to GCP and iterate over to get the best model\n",
    "3. Push everything to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b51fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = DataFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889d110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_class.light_weekly_aggregate_train()\n",
    "val_data = data_class.light_weekly_aggregate_validate()\n",
    "test_data = data_class.light_weekly_aggregate_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c6823e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>TS_mean</th>\n",
       "      <th>WS10M_mean</th>\n",
       "      <th>WS10M_MAX_mean</th>\n",
       "      <th>WS10M_MIN_mean</th>\n",
       "      <th>WS10M_RANGE_mean</th>\n",
       "      <th>WS50M_mean</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1.604286</td>\n",
       "      <td>100.710000</td>\n",
       "      <td>5.791429</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>5.324286</td>\n",
       "      <td>5.141429</td>\n",
       "      <td>13.990000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.744286</td>\n",
       "      <td>2.435714</td>\n",
       "      <td>3.325714</td>\n",
       "      <td>1.715714</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>4.891429</td>\n",
       "      <td>6.487143</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>3.147143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>4.114286</td>\n",
       "      <td>100.555714</td>\n",
       "      <td>5.581429</td>\n",
       "      <td>6.798571</td>\n",
       "      <td>4.468571</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>11.945714</td>\n",
       "      <td>...</td>\n",
       "      <td>6.407143</td>\n",
       "      <td>2.378571</td>\n",
       "      <td>3.431429</td>\n",
       "      <td>1.347143</td>\n",
       "      <td>2.087143</td>\n",
       "      <td>4.317143</td>\n",
       "      <td>6.152857</td>\n",
       "      <td>2.728571</td>\n",
       "      <td>3.425714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>100.705714</td>\n",
       "      <td>4.538571</td>\n",
       "      <td>4.972857</td>\n",
       "      <td>1.648571</td>\n",
       "      <td>1.458571</td>\n",
       "      <td>11.154286</td>\n",
       "      <td>...</td>\n",
       "      <td>4.422857</td>\n",
       "      <td>2.618571</td>\n",
       "      <td>3.755714</td>\n",
       "      <td>1.561429</td>\n",
       "      <td>2.192857</td>\n",
       "      <td>4.744286</td>\n",
       "      <td>7.060000</td>\n",
       "      <td>2.927143</td>\n",
       "      <td>4.135714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>100.631429</td>\n",
       "      <td>5.165714</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.421429</td>\n",
       "      <td>3.234286</td>\n",
       "      <td>13.391429</td>\n",
       "      <td>...</td>\n",
       "      <td>6.021429</td>\n",
       "      <td>1.984286</td>\n",
       "      <td>2.894286</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>1.898571</td>\n",
       "      <td>3.995714</td>\n",
       "      <td>6.041429</td>\n",
       "      <td>1.671429</td>\n",
       "      <td>4.368571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.574286</td>\n",
       "      <td>100.781429</td>\n",
       "      <td>8.638571</td>\n",
       "      <td>13.088571</td>\n",
       "      <td>10.671429</td>\n",
       "      <td>10.484286</td>\n",
       "      <td>18.827143</td>\n",
       "      <td>...</td>\n",
       "      <td>13.062857</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>3.352857</td>\n",
       "      <td>1.805714</td>\n",
       "      <td>1.545714</td>\n",
       "      <td>5.032857</td>\n",
       "      <td>6.378571</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>2.965714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326334</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>49</td>\n",
       "      <td>0.198571</td>\n",
       "      <td>83.754286</td>\n",
       "      <td>1.977143</td>\n",
       "      <td>-2.270000</td>\n",
       "      <td>-11.144286</td>\n",
       "      <td>-6.707143</td>\n",
       "      <td>3.998571</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.080000</td>\n",
       "      <td>2.752857</td>\n",
       "      <td>3.825714</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>2.098571</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>5.825714</td>\n",
       "      <td>2.747143</td>\n",
       "      <td>3.077143</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326335</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>50</td>\n",
       "      <td>0.538571</td>\n",
       "      <td>83.165714</td>\n",
       "      <td>2.172857</td>\n",
       "      <td>-2.527143</td>\n",
       "      <td>-10.194286</td>\n",
       "      <td>-6.361429</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.081429</td>\n",
       "      <td>2.917143</td>\n",
       "      <td>4.511429</td>\n",
       "      <td>1.295714</td>\n",
       "      <td>3.215714</td>\n",
       "      <td>4.381429</td>\n",
       "      <td>6.402857</td>\n",
       "      <td>2.027143</td>\n",
       "      <td>4.378571</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326336</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>51</td>\n",
       "      <td>1.041429</td>\n",
       "      <td>82.821429</td>\n",
       "      <td>2.427143</td>\n",
       "      <td>-3.722857</td>\n",
       "      <td>-8.595714</td>\n",
       "      <td>-6.158571</td>\n",
       "      <td>1.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.297143</td>\n",
       "      <td>3.715714</td>\n",
       "      <td>5.474286</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>3.242857</td>\n",
       "      <td>5.808571</td>\n",
       "      <td>8.092857</td>\n",
       "      <td>3.615714</td>\n",
       "      <td>4.475714</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326337</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>52</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>82.907143</td>\n",
       "      <td>2.564286</td>\n",
       "      <td>-2.982857</td>\n",
       "      <td>-8.382857</td>\n",
       "      <td>-5.681429</td>\n",
       "      <td>2.851429</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.315714</td>\n",
       "      <td>5.145714</td>\n",
       "      <td>7.682857</td>\n",
       "      <td>3.452857</td>\n",
       "      <td>4.227143</td>\n",
       "      <td>7.677143</td>\n",
       "      <td>10.792857</td>\n",
       "      <td>5.254286</td>\n",
       "      <td>5.537143</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326338</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>82.877500</td>\n",
       "      <td>1.847500</td>\n",
       "      <td>-6.230000</td>\n",
       "      <td>-11.977500</td>\n",
       "      <td>-9.105000</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.192500</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>4.212500</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>3.662500</td>\n",
       "      <td>3.542500</td>\n",
       "      <td>5.965000</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326339 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fips_  year_  week_num_  PRECTOT_mean     PS_mean  QV2M_mean  \\\n",
       "0        1001   2019          2      1.604286  100.710000   5.791429   \n",
       "1        1001   2019          3      4.114286  100.555714   5.581429   \n",
       "2        1001   2019          4      7.530000  100.705714   4.538571   \n",
       "3        1001   2019          5      0.878571  100.631429   5.165714   \n",
       "4        1001   2019          6      0.574286  100.781429   8.638571   \n",
       "...       ...    ...        ...           ...         ...        ...   \n",
       "326334  56043   2020         49      0.198571   83.754286   1.977143   \n",
       "326335  56043   2020         50      0.538571   83.165714   2.172857   \n",
       "326336  56043   2020         51      1.041429   82.821429   2.427143   \n",
       "326337  56043   2020         52      0.990000   82.907143   2.564286   \n",
       "326338  56043   2020         53      0.002500   82.877500   1.847500   \n",
       "\n",
       "         T2M_mean  T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...    TS_mean  \\\n",
       "0        7.820000     5.324286     5.141429     13.990000  ...   7.744286   \n",
       "1        6.798571     4.468571     4.340000     11.945714  ...   6.407143   \n",
       "2        4.972857     1.648571     1.458571     11.154286  ...   4.422857   \n",
       "3        6.250000     3.421429     3.234286     13.391429  ...   6.021429   \n",
       "4       13.088571    10.671429    10.484286     18.827143  ...  13.062857   \n",
       "...           ...          ...          ...           ...  ...        ...   \n",
       "326334  -2.270000   -11.144286    -6.707143      3.998571  ...  -4.080000   \n",
       "326335  -2.527143   -10.194286    -6.361429      2.264286  ...  -4.081429   \n",
       "326336  -3.722857    -8.595714    -6.158571      1.544286  ...  -5.297143   \n",
       "326337  -2.982857    -8.382857    -5.681429      2.851429  ...  -4.315714   \n",
       "326338  -6.230000   -11.977500    -9.105000      0.282500  ...  -9.192500   \n",
       "\n",
       "        WS10M_mean  WS10M_MAX_mean  WS10M_MIN_mean  WS10M_RANGE_mean  \\\n",
       "0         2.435714        3.325714        1.715714          1.610000   \n",
       "1         2.378571        3.431429        1.347143          2.087143   \n",
       "2         2.618571        3.755714        1.561429          2.192857   \n",
       "3         1.984286        2.894286        0.992857          1.898571   \n",
       "4         2.570000        3.352857        1.805714          1.545714   \n",
       "...            ...             ...             ...               ...   \n",
       "326334    2.752857        3.825714        1.730000          2.098571   \n",
       "326335    2.917143        4.511429        1.295714          3.215714   \n",
       "326336    3.715714        5.474286        2.230000          3.242857   \n",
       "326337    5.145714        7.682857        3.452857          4.227143   \n",
       "326338    2.405000        4.212500        0.552500          3.662500   \n",
       "\n",
       "        WS50M_mean  WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  \\\n",
       "0         4.891429        6.487143        3.340000          3.147143   \n",
       "1         4.317143        6.152857        2.728571          3.425714   \n",
       "2         4.744286        7.060000        2.927143          4.135714   \n",
       "3         3.995714        6.041429        1.671429          4.368571   \n",
       "4         5.032857        6.378571        3.410000          2.965714   \n",
       "...            ...             ...             ...               ...   \n",
       "326334    4.190000        5.825714        2.747143          3.077143   \n",
       "326335    4.381429        6.402857        2.027143          4.378571   \n",
       "326336    5.808571        8.092857        3.615714          4.475714   \n",
       "326337    7.677143       10.792857        5.254286          5.537143   \n",
       "326338    3.542500        5.965000        0.907500          5.062500   \n",
       "\n",
       "        score_max  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "326334        4.0  \n",
       "326335        4.0  \n",
       "326336        4.0  \n",
       "326337        4.0  \n",
       "326338        4.0  \n",
       "\n",
       "[326339 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc1f83",
   "metadata": {},
   "source": [
    "## Tensorflow window class method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7128a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self,data,input_width,label_width,shift,label_columns=None):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "            self.column_indices = {name: i for i, name in enumerate(self.data.columns)}\n",
    "\n",
    "    \n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    \n",
    "    def split_window(self, list_of_consecutive_inputs_w_labels):\n",
    "        inputs = list_of_consecutive_inputs_w_labels[:, self.input_slice, :]\n",
    "        labels = list_of_consecutive_inputs_w_labels[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns],axis=-1)\n",
    "\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self):\n",
    "        data = np.array(self.data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(data=data,targets=None,\n",
    "                                                              sequence_length=self.total_window_size,\n",
    "          sequence_stride=1,\n",
    "          shuffle=True,\n",
    "          batch_size=32,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e97eac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearning:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        #self.data = DataFunctions().light_weekly_aggregate()\n",
    "        self.features = self.data.drop(columns=['fips_','year','week_num_','score_max']).columns\n",
    "        \n",
    "    def robust(self):\n",
    "        df = self.data.copy()\n",
    "        for f in self.features:\n",
    "            median = np.median(df[f])\n",
    "            IQR = np.subtract(*np.percentile(df[f], [75, 25]))\n",
    "            df[f] = df[f].map(lambda x: (x-median)/IQR)\n",
    "        \n",
    "        self.scaled_data = df\n",
    "            \n",
    "    def preprocess(self):\n",
    "        self.robust()\n",
    "        self.preprocessed_data = WindowGenerator(self.scaled_data,input_width=6, label_width=1, shift=1,label_columns=['score_max']).make_dataset()\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        self.model = models.Sequential()\n",
    "        self.model.add(layers.LSTM(20))\n",
    "        self.model.add(layers.Dense(1,activation='sigmoid'))\n",
    "        self.model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    \n",
    "    def train_model(self):\n",
    "        self.initialize_model()\n",
    "        self.preprocess()\n",
    "        self.model.fit(self.preprocessed_data,epochs=1,batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ff5ea1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_data = robust(train_data)[:int((len(train_data)*0.1))]\n",
    "scaled_val_data = robust(val_data)[:int((len(train_data)*0.1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5fdd6141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ohe train\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "train_ohe = OneHotEncoder(sparse = False)\n",
    "train_ohe.fit(scaled_train_data[['score_max']])\n",
    "scoremax_encoded = train_ohe.transform(scaled_train_data[['score_max']])\n",
    "scaled_train_data[\"score_max_0\"],scaled_train_data[\"score_max_1\"],scaled_train_data['score_max_2'],scaled_train_data['score_max_3'],scaled_train_data['score_max_4'],scaled_train_data['score_max_5'] = scoremax_encoded.T \n",
    "scaled_train_data_ohe = scaled_train_data.drop(columns=['score_max'])\n",
    "\n",
    "#ohe val\n",
    "val_ohe = OneHotEncoder(sparse = False)\n",
    "val_ohe.fit(scaled_val_data[['score_max']])\n",
    "scoremax_encoded = val_ohe.transform(scaled_val_data[['score_max']])\n",
    "scaled_val_data[\"score_max_0\"],scaled_val_data[\"score_max_1\"],scaled_val_data['score_max_2'],scaled_val_data['score_max_3'],scaled_val_data['score_max_4'],scaled_val_data['score_max_5'] = scoremax_encoded.T \n",
    "scaled_val_data_ohe = scaled_val_data.drop(columns=['score_max'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8fcb1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.Dense(20,activation='relu'))\n",
    "    model.add(layers.Dense(6,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "def train_model(train_data,validation_data):\n",
    "    model = initialize_model()\n",
    "    history = model.fit(train_data,validation_data=validation_data,epochs=1000,batch_size=32,callbacks=EarlyStopping(patience=10,restore_best_weights=True),verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "58d24842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DatasetV2.cache of <MapDataset shapes: ((None, 6, 27), (None, 6, 6)), types: (tf.float32, tf.float32)>>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_scaled_ohe = WindowGenerator(scaled_train_data_ohe,input_width=6,label_width=6,shift=1,label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\n",
    "preprocessed_scaled_ohe.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7b1d91af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8615/8615 [==============================] - 126s 14ms/step - loss: 1.3816 - accuracy: 0.5157 - val_loss: 1.1620 - val_accuracy: 0.6767\n",
      "Epoch 2/50\n",
      "8615/8615 [==============================] - 124s 14ms/step - loss: 1.3772 - accuracy: 0.5159 - val_loss: 1.1437 - val_accuracy: 0.6767\n",
      "Epoch 3/50\n",
      "8615/8615 [==============================] - 106s 12ms/step - loss: 1.2577 - accuracy: 0.5426 - val_loss: 1.0943 - val_accuracy: 0.5787\n",
      "Epoch 4/50\n",
      "8615/8615 [==============================] - 125s 15ms/step - loss: 1.0507 - accuracy: 0.6047 - val_loss: 0.9435 - val_accuracy: 0.5975\n",
      "Epoch 5/50\n",
      "8615/8615 [==============================] - 125s 15ms/step - loss: 0.9723 - accuracy: 0.6400 - val_loss: 2.9732 - val_accuracy: 0.1012\n",
      "Epoch 6/50\n",
      "8615/8615 [==============================] - 595s 69ms/step - loss: 0.9235 - accuracy: 0.6580 - val_loss: 2.9261 - val_accuracy: 0.1331\n",
      "Epoch 7/50\n",
      "8615/8615 [==============================] - 124s 14ms/step - loss: 0.8934 - accuracy: 0.6670 - val_loss: 0.8141 - val_accuracy: 0.7111\n",
      "Epoch 8/50\n",
      "8615/8615 [==============================] - 111s 13ms/step - loss: 0.8782 - accuracy: 0.6717 - val_loss: 1.1594 - val_accuracy: 0.4453\n",
      "Epoch 9/50\n",
      "8615/8615 [==============================] - 110s 13ms/step - loss: 0.8699 - accuracy: 0.6755 - val_loss: 2.1137 - val_accuracy: 0.2910\n",
      "Epoch 10/50\n",
      "8615/8615 [==============================] - 109s 13ms/step - loss: 0.8651 - accuracy: 0.6785 - val_loss: 0.8991 - val_accuracy: 0.4573\n",
      "Epoch 11/50\n",
      "8615/8615 [==============================] - 2040s 237ms/step - loss: 0.8533 - accuracy: 0.6856 - val_loss: 2.9087 - val_accuracy: 0.2083\n",
      "Epoch 12/50\n",
      "8615/8615 [==============================] - 114s 13ms/step - loss: 0.8478 - accuracy: 0.6896 - val_loss: 0.8723 - val_accuracy: 0.4716\n",
      "Epoch 13/50\n",
      "8615/8615 [==============================] - 124s 14ms/step - loss: 0.8388 - accuracy: 0.6955 - val_loss: 1.2672 - val_accuracy: 0.3622\n",
      "Epoch 14/50\n",
      "8615/8615 [==============================] - 330s 38ms/step - loss: 0.8302 - accuracy: 0.7013 - val_loss: 4.3805 - val_accuracy: 0.1101\n",
      "Epoch 15/50\n",
      "8615/8615 [==============================] - 114s 13ms/step - loss: 0.8195 - accuracy: 0.7075 - val_loss: 1.2718 - val_accuracy: 0.3731\n",
      "Epoch 16/50\n",
      "8615/8615 [==============================] - 110s 13ms/step - loss: 0.8135 - accuracy: 0.7109 - val_loss: 1.1674 - val_accuracy: 0.4618\n",
      "Epoch 17/50\n",
      "8615/8615 [==============================] - 110s 13ms/step - loss: 0.8059 - accuracy: 0.7139 - val_loss: 1.6504 - val_accuracy: 0.3171\n"
     ]
    }
   ],
   "source": [
    "hist = train_model(preprocessed_train_ohe,preprocessed_val_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "608f492f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17cfa1e20>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predicted_classes = model.predict(X_test > 0.5).astype(\"int32\")[:, 0]\n",
    "#print(f'test recall score = {recall_score(y_test,predicted_classes)}')\n",
    "fig, ax = plt.subplots(1,2,figsize=(13,5))\n",
    "ax[0].plot(hist.history['loss'],label='train_loss')\n",
    "ax[0].plot(hist.history['val_loss'],label='val_loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(hist.history['accuracy'],label='train_accuracy')\n",
    "ax[1].plot(hist.history['val_accuracy'],label='val_accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7ccf0502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>TS_mean</th>\n",
       "      <th>WS10M_mean</th>\n",
       "      <th>WS10M_MAX_mean</th>\n",
       "      <th>WS10M_MIN_mean</th>\n",
       "      <th>WS10M_RANGE_mean</th>\n",
       "      <th>WS50M_mean</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.261429</td>\n",
       "      <td>100.702857</td>\n",
       "      <td>6.491429</td>\n",
       "      <td>9.878571</td>\n",
       "      <td>5.648571</td>\n",
       "      <td>5.674286</td>\n",
       "      <td>16.345714</td>\n",
       "      <td>...</td>\n",
       "      <td>9.397143</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>3.722857</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>2.201429</td>\n",
       "      <td>5.044286</td>\n",
       "      <td>6.934286</td>\n",
       "      <td>2.815714</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.554286</td>\n",
       "      <td>101.100000</td>\n",
       "      <td>6.104286</td>\n",
       "      <td>9.662857</td>\n",
       "      <td>5.527143</td>\n",
       "      <td>5.552857</td>\n",
       "      <td>16.751429</td>\n",
       "      <td>...</td>\n",
       "      <td>9.431429</td>\n",
       "      <td>2.472857</td>\n",
       "      <td>3.585714</td>\n",
       "      <td>1.568571</td>\n",
       "      <td>2.018571</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>7.162857</td>\n",
       "      <td>2.968571</td>\n",
       "      <td>4.192857</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.017143</td>\n",
       "      <td>100.348571</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>4.834286</td>\n",
       "      <td>4.890000</td>\n",
       "      <td>13.738571</td>\n",
       "      <td>...</td>\n",
       "      <td>8.194286</td>\n",
       "      <td>2.507143</td>\n",
       "      <td>3.574286</td>\n",
       "      <td>1.461429</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>4.702857</td>\n",
       "      <td>6.682857</td>\n",
       "      <td>2.997143</td>\n",
       "      <td>3.685714</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.742857</td>\n",
       "      <td>100.755714</td>\n",
       "      <td>3.072857</td>\n",
       "      <td>0.737143</td>\n",
       "      <td>-3.367143</td>\n",
       "      <td>-3.265714</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>2.774286</td>\n",
       "      <td>3.908571</td>\n",
       "      <td>1.664286</td>\n",
       "      <td>2.248571</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>6.727143</td>\n",
       "      <td>3.244286</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.012857</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.501429</td>\n",
       "      <td>-2.685714</td>\n",
       "      <td>-2.627143</td>\n",
       "      <td>10.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.021429</td>\n",
       "      <td>2.211429</td>\n",
       "      <td>3.161429</td>\n",
       "      <td>1.225714</td>\n",
       "      <td>1.934286</td>\n",
       "      <td>4.125714</td>\n",
       "      <td>5.971429</td>\n",
       "      <td>2.045714</td>\n",
       "      <td>3.927143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759898</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>48</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>82.517143</td>\n",
       "      <td>2.265714</td>\n",
       "      <td>-3.541429</td>\n",
       "      <td>-9.130000</td>\n",
       "      <td>-9.007143</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.108571</td>\n",
       "      <td>4.227143</td>\n",
       "      <td>6.260000</td>\n",
       "      <td>2.197143</td>\n",
       "      <td>4.057143</td>\n",
       "      <td>6.231429</td>\n",
       "      <td>8.827143</td>\n",
       "      <td>3.687143</td>\n",
       "      <td>5.140000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759899</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>49</td>\n",
       "      <td>0.624286</td>\n",
       "      <td>82.787143</td>\n",
       "      <td>1.841429</td>\n",
       "      <td>-8.072857</td>\n",
       "      <td>-12.847143</td>\n",
       "      <td>-12.498571</td>\n",
       "      <td>-3.115714</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.557143</td>\n",
       "      <td>3.268571</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>1.485714</td>\n",
       "      <td>3.704286</td>\n",
       "      <td>4.784286</td>\n",
       "      <td>7.161429</td>\n",
       "      <td>2.328571</td>\n",
       "      <td>4.831429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759900</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>50</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>82.602857</td>\n",
       "      <td>1.574286</td>\n",
       "      <td>-10.298571</td>\n",
       "      <td>-14.704286</td>\n",
       "      <td>-14.268571</td>\n",
       "      <td>-4.091429</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.231429</td>\n",
       "      <td>3.212857</td>\n",
       "      <td>5.612857</td>\n",
       "      <td>1.051429</td>\n",
       "      <td>4.561429</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>7.524286</td>\n",
       "      <td>1.565714</td>\n",
       "      <td>5.957143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759901</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>51</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>82.742857</td>\n",
       "      <td>2.201429</td>\n",
       "      <td>-5.717143</td>\n",
       "      <td>-9.964286</td>\n",
       "      <td>-9.821429</td>\n",
       "      <td>0.598571</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.302857</td>\n",
       "      <td>4.641429</td>\n",
       "      <td>6.664286</td>\n",
       "      <td>2.394286</td>\n",
       "      <td>4.268571</td>\n",
       "      <td>6.905714</td>\n",
       "      <td>9.538571</td>\n",
       "      <td>4.108571</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759902</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>82.945000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>-7.315000</td>\n",
       "      <td>-12.325000</td>\n",
       "      <td>-12.048333</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.206667</td>\n",
       "      <td>4.590000</td>\n",
       "      <td>6.711667</td>\n",
       "      <td>2.478333</td>\n",
       "      <td>4.235000</td>\n",
       "      <td>6.828333</td>\n",
       "      <td>9.515000</td>\n",
       "      <td>4.071667</td>\n",
       "      <td>5.443333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756796 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fips_  year_  week_num_  PRECTOT_mean     PS_mean  QV2M_mean  \\\n",
       "0         1001   2000          1      5.261429  100.702857   6.491429   \n",
       "1         1001   2000          2      3.554286  101.100000   6.104286   \n",
       "2         1001   2000          3      4.017143  100.348571   6.090000   \n",
       "3         1001   2000          4      3.742857  100.755714   3.072857   \n",
       "4         1001   2000          5      0.000000  101.012857   3.142857   \n",
       "...        ...    ...        ...           ...         ...        ...   \n",
       "2759898  56043   2016         48      0.211429   82.517143   2.265714   \n",
       "2759899  56043   2016         49      0.624286   82.787143   1.841429   \n",
       "2759900  56043   2016         50      0.754286   82.602857   1.574286   \n",
       "2759901  56043   2016         51      0.775714   82.742857   2.201429   \n",
       "2759902  56043   2016         52      0.326667   82.945000   1.750000   \n",
       "\n",
       "          T2M_mean  T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...    TS_mean  \\\n",
       "0         9.878571     5.648571     5.674286     16.345714  ...   9.397143   \n",
       "1         9.662857     5.527143     5.552857     16.751429  ...   9.431429   \n",
       "2         8.270000     4.834286     4.890000     13.738571  ...   8.194286   \n",
       "3         0.737143    -3.367143    -3.265714      5.570000  ...   0.817143   \n",
       "4         2.501429    -2.685714    -2.627143     10.460000  ...   2.021429   \n",
       "...            ...          ...          ...           ...  ...        ...   \n",
       "2759898  -3.541429    -9.130000    -9.007143      0.507143  ...  -4.108571   \n",
       "2759899  -8.072857   -12.847143   -12.498571     -3.115714  ...  -8.557143   \n",
       "2759900 -10.298571   -14.704286   -14.268571     -4.091429  ... -11.231429   \n",
       "2759901  -5.717143    -9.964286    -9.821429      0.598571  ...  -7.302857   \n",
       "2759902  -7.315000   -12.325000   -12.048333     -0.335000  ...  -9.206667   \n",
       "\n",
       "         WS10M_mean  WS10M_MAX_mean  WS10M_MIN_mean  WS10M_RANGE_mean  \\\n",
       "0          2.630000        3.722857        1.520000          2.201429   \n",
       "1          2.472857        3.585714        1.568571          2.018571   \n",
       "2          2.507143        3.574286        1.461429          2.110000   \n",
       "3          2.774286        3.908571        1.664286          2.248571   \n",
       "4          2.211429        3.161429        1.225714          1.934286   \n",
       "...             ...             ...             ...               ...   \n",
       "2759898    4.227143        6.260000        2.197143          4.057143   \n",
       "2759899    3.268571        5.190000        1.485714          3.704286   \n",
       "2759900    3.212857        5.612857        1.051429          4.561429   \n",
       "2759901    4.641429        6.664286        2.394286          4.268571   \n",
       "2759902    4.590000        6.711667        2.478333          4.235000   \n",
       "\n",
       "         WS50M_mean  WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  \\\n",
       "0          5.044286        6.934286        2.815714          4.120000   \n",
       "1          5.142857        7.162857        2.968571          4.192857   \n",
       "2          4.702857        6.682857        2.997143          3.685714   \n",
       "3          4.928571        6.727143        3.244286          3.480000   \n",
       "4          4.125714        5.971429        2.045714          3.927143   \n",
       "...             ...             ...             ...               ...   \n",
       "2759898    6.231429        8.827143        3.687143          5.140000   \n",
       "2759899    4.784286        7.161429        2.328571          4.831429   \n",
       "2759900    4.600000        7.524286        1.565714          5.957143   \n",
       "2759901    6.905714        9.538571        4.108571          5.428571   \n",
       "2759902    6.828333        9.515000        4.071667          5.443333   \n",
       "\n",
       "         score_max  \n",
       "0              1.0  \n",
       "1              2.0  \n",
       "2              2.0  \n",
       "3              2.0  \n",
       "4              1.0  \n",
       "...            ...  \n",
       "2759898        0.0  \n",
       "2759899        0.0  \n",
       "2759900        0.0  \n",
       "2759901        0.0  \n",
       "2759902        0.0  \n",
       "\n",
       "[2756796 rows x 22 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "37468d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>WS50M_mean</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max_0</th>\n",
       "      <th>score_max_1</th>\n",
       "      <th>score_max_2</th>\n",
       "      <th>score_max_3</th>\n",
       "      <th>score_max_4</th>\n",
       "      <th>score_max_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.078902</td>\n",
       "      <td>0.591231</td>\n",
       "      <td>-0.067941</td>\n",
       "      <td>-0.230095</td>\n",
       "      <td>-0.112909</td>\n",
       "      <td>-0.112313</td>\n",
       "      <td>-0.219685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129051</td>\n",
       "      <td>-0.194828</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>-0.155185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566467</td>\n",
       "      <td>0.689533</td>\n",
       "      <td>-0.123068</td>\n",
       "      <td>-0.242940</td>\n",
       "      <td>-0.120815</td>\n",
       "      <td>-0.120243</td>\n",
       "      <td>-0.195707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089120</td>\n",
       "      <td>-0.125862</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>-0.118202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.503536</td>\n",
       "      <td>-0.125102</td>\n",
       "      <td>-0.325876</td>\n",
       "      <td>-0.165923</td>\n",
       "      <td>-0.163526</td>\n",
       "      <td>-0.373768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267361</td>\n",
       "      <td>-0.270690</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.375635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.623070</td>\n",
       "      <td>0.604314</td>\n",
       "      <td>-0.554719</td>\n",
       "      <td>-0.774413</td>\n",
       "      <td>-0.699870</td>\n",
       "      <td>-0.696082</td>\n",
       "      <td>-0.856534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175926</td>\n",
       "      <td>-0.257328</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>-0.480058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.500429</td>\n",
       "      <td>0.667963</td>\n",
       "      <td>-0.544752</td>\n",
       "      <td>-0.669360</td>\n",
       "      <td>-0.655506</td>\n",
       "      <td>-0.654384</td>\n",
       "      <td>-0.567533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501157</td>\n",
       "      <td>-0.485345</td>\n",
       "      <td>-0.556951</td>\n",
       "      <td>-0.253082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275984</th>\n",
       "      <td>12041</td>\n",
       "      <td>2013</td>\n",
       "      <td>27</td>\n",
       "      <td>4.312607</td>\n",
       "      <td>0.796676</td>\n",
       "      <td>1.561839</td>\n",
       "      <td>0.707298</td>\n",
       "      <td>1.049200</td>\n",
       "      <td>1.051679</td>\n",
       "      <td>0.526753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330440</td>\n",
       "      <td>-0.628879</td>\n",
       "      <td>0.214405</td>\n",
       "      <td>-1.163162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275985</th>\n",
       "      <td>12041</td>\n",
       "      <td>2013</td>\n",
       "      <td>28</td>\n",
       "      <td>2.399657</td>\n",
       "      <td>0.756365</td>\n",
       "      <td>1.504475</td>\n",
       "      <td>0.765652</td>\n",
       "      <td>1.022600</td>\n",
       "      <td>1.024907</td>\n",
       "      <td>0.640057</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034144</td>\n",
       "      <td>-1.075000</td>\n",
       "      <td>-0.664992</td>\n",
       "      <td>-1.151559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275986</th>\n",
       "      <td>12041</td>\n",
       "      <td>2013</td>\n",
       "      <td>29</td>\n",
       "      <td>1.988851</td>\n",
       "      <td>0.825672</td>\n",
       "      <td>1.487795</td>\n",
       "      <td>0.713678</td>\n",
       "      <td>1.019252</td>\n",
       "      <td>1.021549</td>\n",
       "      <td>0.563311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503472</td>\n",
       "      <td>-0.747414</td>\n",
       "      <td>0.067002</td>\n",
       "      <td>-1.235678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275987</th>\n",
       "      <td>12041</td>\n",
       "      <td>2013</td>\n",
       "      <td>30</td>\n",
       "      <td>2.430532</td>\n",
       "      <td>0.717115</td>\n",
       "      <td>1.593369</td>\n",
       "      <td>0.758506</td>\n",
       "      <td>1.058315</td>\n",
       "      <td>1.060728</td>\n",
       "      <td>0.594044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587963</td>\n",
       "      <td>-0.752155</td>\n",
       "      <td>-0.114740</td>\n",
       "      <td>-1.086294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275988</th>\n",
       "      <td>12041</td>\n",
       "      <td>2013</td>\n",
       "      <td>31</td>\n",
       "      <td>1.033448</td>\n",
       "      <td>0.775813</td>\n",
       "      <td>1.625305</td>\n",
       "      <td>0.837955</td>\n",
       "      <td>1.073010</td>\n",
       "      <td>1.075466</td>\n",
       "      <td>0.724318</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.092593</td>\n",
       "      <td>-1.126724</td>\n",
       "      <td>-0.880235</td>\n",
       "      <td>-1.052937</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275679 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fips_  year_  week_num_  PRECTOT_mean   PS_mean  QV2M_mean  T2M_mean  \\\n",
       "0        1001   2000          1      1.078902  0.591231  -0.067941 -0.230095   \n",
       "1        1001   2000          2      0.566467  0.689533  -0.123068 -0.242940   \n",
       "2        1001   2000          3      0.705403  0.503536  -0.125102 -0.325876   \n",
       "3        1001   2000          4      0.623070  0.604314  -0.554719 -0.774413   \n",
       "4        1001   2000          5     -0.500429  0.667963  -0.544752 -0.669360   \n",
       "...       ...    ...        ...           ...       ...        ...       ...   \n",
       "275984  12041   2013         27      4.312607  0.796676   1.561839  0.707298   \n",
       "275985  12041   2013         28      2.399657  0.756365   1.504475  0.765652   \n",
       "275986  12041   2013         29      1.988851  0.825672   1.487795  0.713678   \n",
       "275987  12041   2013         30      2.430532  0.717115   1.593369  0.758506   \n",
       "275988  12041   2013         31      1.033448  0.775813   1.625305  0.837955   \n",
       "\n",
       "        T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...  WS50M_mean  \\\n",
       "0         -0.112909    -0.112313     -0.219685  ...   -0.129051   \n",
       "1         -0.120815    -0.120243     -0.195707  ...   -0.089120   \n",
       "2         -0.165923    -0.163526     -0.373768  ...   -0.267361   \n",
       "3         -0.699870    -0.696082     -0.856534  ...   -0.175926   \n",
       "4         -0.655506    -0.654384     -0.567533  ...   -0.501157   \n",
       "...             ...          ...           ...  ...         ...   \n",
       "275984     1.049200     1.051679      0.526753  ...   -0.330440   \n",
       "275985     1.022600     1.024907      0.640057  ...   -1.034144   \n",
       "275986     1.019252     1.021549      0.563311  ...   -0.503472   \n",
       "275987     1.058315     1.060728      0.594044  ...   -0.587963   \n",
       "275988     1.073010     1.075466      0.724318  ...   -1.092593   \n",
       "\n",
       "        WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  score_max_0  \\\n",
       "0            -0.194828       -0.105528         -0.155185          0.0   \n",
       "1            -0.125862       -0.015913         -0.118202          0.0   \n",
       "2            -0.270690        0.000838         -0.375635          0.0   \n",
       "3            -0.257328        0.145729         -0.480058          0.0   \n",
       "4            -0.485345       -0.556951         -0.253082          0.0   \n",
       "...                ...             ...               ...          ...   \n",
       "275984       -0.628879        0.214405         -1.163162          1.0   \n",
       "275985       -1.075000       -0.664992         -1.151559          1.0   \n",
       "275986       -0.747414        0.067002         -1.235678          1.0   \n",
       "275987       -0.752155       -0.114740         -1.086294          1.0   \n",
       "275988       -1.126724       -0.880235         -1.052937          1.0   \n",
       "\n",
       "        score_max_1  score_max_2  score_max_3  score_max_4  score_max_5  \n",
       "0               1.0          0.0          0.0          0.0          0.0  \n",
       "1               0.0          1.0          0.0          0.0          0.0  \n",
       "2               0.0          1.0          0.0          0.0          0.0  \n",
       "3               0.0          1.0          0.0          0.0          0.0  \n",
       "4               1.0          0.0          0.0          0.0          0.0  \n",
       "...             ...          ...          ...          ...          ...  \n",
       "275984          0.0          0.0          0.0          0.0          0.0  \n",
       "275985          0.0          0.0          0.0          0.0          0.0  \n",
       "275986          0.0          0.0          0.0          0.0          0.0  \n",
       "275987          0.0          0.0          0.0          0.0          0.0  \n",
       "275988          0.0          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[275679 rows x 27 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_data_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "21dc96a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mall_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p9/9fqg02b5193fw889mjw1vkrw0000gn/T/ipykernel_57803/229474102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mfinal_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'window_generator'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KerasClassifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_wrapper_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mfinal_pipe_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mfinal_pipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mall_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             raise ValueError(\"Specifying the columns using strings is only \"\n\u001b[0m\u001b[1;32m    377\u001b[0m                              \"supported for pandas DataFrames\")\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "\n",
    "\n",
    "class Window(): \n",
    "    \n",
    "    def fit(self,data):\n",
    "        self.data = data\n",
    "        self.window = WindowGenerator(self.data,input_width=6,label_width=6,shift=1,label_columns=['score_max_0','score_max_1','score_max_2','score_max_3','score_max_4','score_max_5'])\n",
    "        return self\n",
    " \n",
    "    def transform(self,data):\n",
    "        data_windowed = self.window.make_dataset()\n",
    "        return data_windowed\n",
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.Dense(20,activation='relu'))\n",
    "    model.add(layers.Dense(6,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "scaling_pipe = Pipeline([('robust_scaler',RobustScaler())])\n",
    "encoder = Pipeline([('ohe',OneHotEncoder())])\n",
    "preprocessor = ColumnTransformer([('scaling',scaling_pipe,train_data.drop(columns=['fips_','year_','week_num_','score_max']).columns),('cat_encoder',encoder,['score_max'])],remainder='passthrough')\n",
    "\n",
    "window_generator = Pipeline([('window',Window())])\n",
    "windower = ColumnTransformer([('window',window_generator,[col for col in scaled_train_data_ohe.columns])])\n",
    "\n",
    "keras_wrapper_model = KerasClassifier(build_fn=initialize_model,epochs=1,batch_size=32,callbacks=EarlyStopping(patience=10,restore_best_weights=True),verbose=1)\n",
    "\n",
    "final_pipe = Pipeline([('preprocessing', preprocessor),('window_generator',windower),('KerasClassifier', keras_wrapper_model)])\n",
    "final_pipe_trained = final_pipe.fit(train_data)\n",
    "final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ef64810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 {color: black;background-color: white;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 pre{padding: 0;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-toggleable {background-color: white;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-item {z-index: 1;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-parallel-item:only-child::after {width: 0;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-4c208d66-b758-406b-b6c9-fdf55eae3c21 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-4c208d66-b758-406b-b6c9-fdf55eae3c21\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"62bf896b-4222-414e-9d18-194c08be4798\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"62bf896b-4222-414e-9d18-194c08be4798\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('window',\n",
       "                                 Pipeline(steps=[('window',\n",
       "                                                  <__main__.Window object at 0x164e22a60>)]),\n",
       "                                 ['fips_', 'year_', 'week_num_', 'PRECTOT_mean',\n",
       "                                  'PS_mean', 'QV2M_mean', 'T2M_mean',\n",
       "                                  'T2MDEW_mean', 'T2MWET_mean', 'T2M_MAX_mean',\n",
       "                                  'T2M_MIN_mean', 'T2M_RANGE_mean', 'TS_mean',\n",
       "                                  'WS10M_mean', 'WS10M_MAX_mean',\n",
       "                                  'WS10M_MIN_mean', 'WS10M_RANGE_mean',\n",
       "                                  'WS50M_mean', 'WS50M_MAX_mean',\n",
       "                                  'WS50M_MIN_mean', 'WS50M_RANGE_mean',\n",
       "                                  'score_max_0', 'score_max_1', 'score_max_2',\n",
       "                                  'score_max_3', 'score_max_4',\n",
       "                                  'score_max_5'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"57cbe440-ee0b-43ea-ba75-ad1037a6f0a7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"57cbe440-ee0b-43ea-ba75-ad1037a6f0a7\">window</label><div class=\"sk-toggleable__content\"><pre>['fips_', 'year_', 'week_num_', 'PRECTOT_mean', 'PS_mean', 'QV2M_mean', 'T2M_mean', 'T2MDEW_mean', 'T2MWET_mean', 'T2M_MAX_mean', 'T2M_MIN_mean', 'T2M_RANGE_mean', 'TS_mean', 'WS10M_mean', 'WS10M_MAX_mean', 'WS10M_MIN_mean', 'WS10M_RANGE_mean', 'WS50M_mean', 'WS50M_MAX_mean', 'WS50M_MIN_mean', 'WS50M_RANGE_mean', 'score_max_0', 'score_max_1', 'score_max_2', 'score_max_3', 'score_max_4', 'score_max_5']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0f047d61-142f-4b6a-bfb6-b8fc0e852773\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0f047d61-142f-4b6a-bfb6-b8fc0e852773\">Window</label><div class=\"sk-toggleable__content\"><pre><__main__.Window object at 0x164e22a60></pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('window',\n",
       "                                 Pipeline(steps=[('window',\n",
       "                                                  <__main__.Window object at 0x164e22a60>)]),\n",
       "                                 ['fips_', 'year_', 'week_num_', 'PRECTOT_mean',\n",
       "                                  'PS_mean', 'QV2M_mean', 'T2M_mean',\n",
       "                                  'T2MDEW_mean', 'T2MWET_mean', 'T2M_MAX_mean',\n",
       "                                  'T2M_MIN_mean', 'T2M_RANGE_mean', 'TS_mean',\n",
       "                                  'WS10M_mean', 'WS10M_MAX_mean',\n",
       "                                  'WS10M_MIN_mean', 'WS10M_RANGE_mean',\n",
       "                                  'WS50M_mean', 'WS50M_MAX_mean',\n",
       "                                  'WS50M_MIN_mean', 'WS50M_RANGE_mean',\n",
       "                                  'score_max_0', 'score_max_1', 'score_max_2',\n",
       "                                  'score_max_3', 'score_max_4',\n",
       "                                  'score_max_5'])])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ColumnTransformer([('window',window_generator,[col for col in scaled_train_data_ohe.columns])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1a1bf0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Window(): \n",
    "    \n",
    "    def fit(self,data):\n",
    "        self.data = data\n",
    "        self.w = WindowGenerator(self.data,input_width=6,label_width=6,shift=1,label_columns=['score_max_0','score_max_1','score_max_2','score_max_3','score_max_4','score_max_5'])\n",
    "        return self\n",
    " \n",
    "    def transform(self,data):\n",
    "        data_windowed = self.w.make_dataset()\n",
    "        return data_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8e409e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 6, 27), (None, 6, 6)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Window()\n",
    "s.fit(scaled_train_data_ohe)\n",
    "sa = s.transform(scaled_train_data_ohe)\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e4dddb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-02 18:36:02.238457: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 6, 27), (None, 6, 6)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Window()\n",
    "d.fit(scaled_train_data_ohe)\n",
    "d.transform(scaled_train_data_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "66fe507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_pipe = Pipeline([('robust_scaler',RobustScaler())])\n",
    "preped_data = ColumnTransformer([('scaling',scaling_pipe,train_data.drop(columns=['fips_','year_','week_num_','score_max']).columns)],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3f926d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('scaling',\n",
       "                                 Pipeline(steps=[('robust_scaler',\n",
       "                                                  RobustScaler())]),\n",
       "                                 Index(['PRECTOT_mean', 'PS_mean', 'QV2M_mean', 'T2M_mean', 'T2MDEW_mean',\n",
       "       'T2MWET_mean', 'T2M_MAX_mean', 'T2M_MIN_mean', 'T2M_RANGE_mean',\n",
       "       'TS_mean', 'WS10M_mean', 'WS10M_MAX_mean', 'WS10M_MIN_mean',\n",
       "       'WS10M_RANGE_mean', 'WS50M_mean', 'WS50M_MAX_mean', 'WS50M_MIN_mean',\n",
       "       'WS50M_RANGE_mean'],\n",
       "      dtype='object'))])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8a389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25f6c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scaler = CustomScaler(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11e8c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scaler.fit()\n",
    "scaled = custom_scaler.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "35efc5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.078902</td>\n",
       "      <td>0.591231</td>\n",
       "      <td>-0.067941</td>\n",
       "      <td>-0.230095</td>\n",
       "      <td>-0.112909</td>\n",
       "      <td>-0.112313</td>\n",
       "      <td>-0.219685</td>\n",
       "      <td>-0.258804</td>\n",
       "      <td>0.360444</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230955</td>\n",
       "      <td>-0.388817</td>\n",
       "      <td>-0.129051</td>\n",
       "      <td>-0.194828</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>-0.155185</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.566467</td>\n",
       "      <td>0.689533</td>\n",
       "      <td>-0.123068</td>\n",
       "      <td>-0.242940</td>\n",
       "      <td>-0.120815</td>\n",
       "      <td>-0.120243</td>\n",
       "      <td>-0.195707</td>\n",
       "      <td>-0.303309</td>\n",
       "      <td>0.652126</td>\n",
       "      <td>-0.253813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189843</td>\n",
       "      <td>-0.471080</td>\n",
       "      <td>-0.089120</td>\n",
       "      <td>-0.125862</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>-0.118202</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.503536</td>\n",
       "      <td>-0.125102</td>\n",
       "      <td>-0.325876</td>\n",
       "      <td>-0.165923</td>\n",
       "      <td>-0.163526</td>\n",
       "      <td>-0.373768</td>\n",
       "      <td>-0.311538</td>\n",
       "      <td>-0.094270</td>\n",
       "      <td>-0.325998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280532</td>\n",
       "      <td>-0.429949</td>\n",
       "      <td>-0.267361</td>\n",
       "      <td>-0.270690</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.375635</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.623070</td>\n",
       "      <td>0.604314</td>\n",
       "      <td>-0.554719</td>\n",
       "      <td>-0.774413</td>\n",
       "      <td>-0.699870</td>\n",
       "      <td>-0.696082</td>\n",
       "      <td>-0.856534</td>\n",
       "      <td>-0.690320</td>\n",
       "      <td>-0.625139</td>\n",
       "      <td>-0.756439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108827</td>\n",
       "      <td>-0.367609</td>\n",
       "      <td>-0.175926</td>\n",
       "      <td>-0.257328</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>-0.480058</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.500429</td>\n",
       "      <td>0.667963</td>\n",
       "      <td>-0.544752</td>\n",
       "      <td>-0.669360</td>\n",
       "      <td>-0.655506</td>\n",
       "      <td>-0.654384</td>\n",
       "      <td>-0.567533</td>\n",
       "      <td>-0.722704</td>\n",
       "      <td>0.775231</td>\n",
       "      <td>-0.686172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.480048</td>\n",
       "      <td>-0.508997</td>\n",
       "      <td>-0.501157</td>\n",
       "      <td>-0.485345</td>\n",
       "      <td>-0.556951</td>\n",
       "      <td>-0.253082</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756791</th>\n",
       "      <td>-0.436964</td>\n",
       "      <td>-3.910184</td>\n",
       "      <td>-0.669650</td>\n",
       "      <td>-1.029177</td>\n",
       "      <td>-1.075056</td>\n",
       "      <td>-1.070989</td>\n",
       "      <td>-1.155751</td>\n",
       "      <td>-0.924792</td>\n",
       "      <td>-0.955268</td>\n",
       "      <td>-1.043844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342201</td>\n",
       "      <td>0.446015</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.376293</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.362582</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756792</th>\n",
       "      <td>-0.313036</td>\n",
       "      <td>-3.843352</td>\n",
       "      <td>-0.730065</td>\n",
       "      <td>-1.298996</td>\n",
       "      <td>-1.317057</td>\n",
       "      <td>-1.298974</td>\n",
       "      <td>-1.369863</td>\n",
       "      <td>-1.257388</td>\n",
       "      <td>-0.503142</td>\n",
       "      <td>-1.303409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>0.287275</td>\n",
       "      <td>-0.234375</td>\n",
       "      <td>-0.126293</td>\n",
       "      <td>-0.391122</td>\n",
       "      <td>0.205946</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756793</th>\n",
       "      <td>-0.274014</td>\n",
       "      <td>-3.888967</td>\n",
       "      <td>-0.768104</td>\n",
       "      <td>-1.431524</td>\n",
       "      <td>-1.437965</td>\n",
       "      <td>-1.414552</td>\n",
       "      <td>-1.427528</td>\n",
       "      <td>-1.448416</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>-1.459448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.627570</td>\n",
       "      <td>0.672879</td>\n",
       "      <td>-0.309028</td>\n",
       "      <td>-0.016810</td>\n",
       "      <td>-0.838358</td>\n",
       "      <td>0.777375</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756794</th>\n",
       "      <td>-0.267581</td>\n",
       "      <td>-3.854314</td>\n",
       "      <td>-0.678804</td>\n",
       "      <td>-1.158727</td>\n",
       "      <td>-1.129371</td>\n",
       "      <td>-1.124160</td>\n",
       "      <td>-1.150347</td>\n",
       "      <td>-1.188374</td>\n",
       "      <td>0.169316</td>\n",
       "      <td>-1.230224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509069</td>\n",
       "      <td>0.541131</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.590948</td>\n",
       "      <td>0.652429</td>\n",
       "      <td>0.509065</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756795</th>\n",
       "      <td>-0.402373</td>\n",
       "      <td>-3.804279</td>\n",
       "      <td>-0.743084</td>\n",
       "      <td>-1.253870</td>\n",
       "      <td>-1.283064</td>\n",
       "      <td>-1.269574</td>\n",
       "      <td>-1.205522</td>\n",
       "      <td>-1.239176</td>\n",
       "      <td>0.139988</td>\n",
       "      <td>-1.341308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580210</td>\n",
       "      <td>0.526028</td>\n",
       "      <td>0.593654</td>\n",
       "      <td>0.583836</td>\n",
       "      <td>0.630793</td>\n",
       "      <td>0.516558</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756796 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "0        1.078902  0.591231 -0.067941 -0.230095 -0.112909 -0.112313 -0.219685   \n",
       "1        0.566467  0.689533 -0.123068 -0.242940 -0.120815 -0.120243 -0.195707   \n",
       "2        0.705403  0.503536 -0.125102 -0.325876 -0.165923 -0.163526 -0.373768   \n",
       "3        0.623070  0.604314 -0.554719 -0.774413 -0.699870 -0.696082 -0.856534   \n",
       "4       -0.500429  0.667963 -0.544752 -0.669360 -0.655506 -0.654384 -0.567533   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "2756791 -0.436964 -3.910184 -0.669650 -1.029177 -1.075056 -1.070989 -1.155751   \n",
       "2756792 -0.313036 -3.843352 -0.730065 -1.298996 -1.317057 -1.298974 -1.369863   \n",
       "2756793 -0.274014 -3.888967 -0.768104 -1.431524 -1.437965 -1.414552 -1.427528   \n",
       "2756794 -0.267581 -3.854314 -0.678804 -1.158727 -1.129371 -1.124160 -1.150347   \n",
       "2756795 -0.402373 -3.804279 -0.743084 -1.253870 -1.283064 -1.269574 -1.205522   \n",
       "\n",
       "                7         8         9  ...        12        13        14  \\\n",
       "0       -0.258804  0.360444 -0.255814  ... -0.230955 -0.388817 -0.129051   \n",
       "1       -0.303309  0.652126 -0.253813  ... -0.189843 -0.471080 -0.089120   \n",
       "2       -0.311538 -0.094270 -0.325998  ... -0.280532 -0.429949 -0.267361   \n",
       "3       -0.690320 -0.625139 -0.756439  ... -0.108827 -0.367609 -0.175926   \n",
       "4       -0.722704  0.775231 -0.686172  ... -0.480048 -0.508997 -0.501157   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "2756791 -0.924792 -0.955268 -1.043844  ...  0.342201  0.446015  0.351852   \n",
       "2756792 -1.257388 -0.503142 -1.303409  ... -0.259976  0.287275 -0.234375   \n",
       "2756793 -1.448416  0.041774 -1.459448  ... -0.627570  0.672879 -0.309028   \n",
       "2756794 -1.188374  0.169316 -1.230224  ...  0.509069  0.541131  0.625000   \n",
       "2756795 -1.239176  0.139988 -1.341308  ...  0.580210  0.526028  0.593654   \n",
       "\n",
       "               15        16        17    fips_   year_  week_num_  score_max  \n",
       "0       -0.194828 -0.105528 -0.155185   1001.0  2000.0        1.0        1.0  \n",
       "1       -0.125862 -0.015913 -0.118202   1001.0  2000.0        2.0        2.0  \n",
       "2       -0.270690  0.000838 -0.375635   1001.0  2000.0        3.0        2.0  \n",
       "3       -0.257328  0.145729 -0.480058   1001.0  2000.0        4.0        2.0  \n",
       "4       -0.485345 -0.556951 -0.253082   1001.0  2000.0        5.0        1.0  \n",
       "...           ...       ...       ...      ...     ...        ...        ...  \n",
       "2756791  0.376293  0.405360  0.362582  56037.0  2008.0       23.0        2.0  \n",
       "2756792 -0.126293 -0.391122  0.205946  56037.0  2008.0       24.0        2.0  \n",
       "2756793 -0.016810 -0.838358  0.777375  56037.0  2008.0       25.0        2.0  \n",
       "2756794  0.590948  0.652429  0.509065  56037.0  2008.0       26.0        2.0  \n",
       "2756795  0.583836  0.630793  0.516558  56037.0  2008.0       27.0        2.0  \n",
       "\n",
       "[2756796 rows x 22 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "feceed39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>TS_mean</th>\n",
       "      <th>WS10M_mean</th>\n",
       "      <th>WS10M_MAX_mean</th>\n",
       "      <th>WS10M_MIN_mean</th>\n",
       "      <th>WS10M_RANGE_mean</th>\n",
       "      <th>WS50M_mean</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.078902</td>\n",
       "      <td>0.591231</td>\n",
       "      <td>-0.067941</td>\n",
       "      <td>-0.230095</td>\n",
       "      <td>-0.112909</td>\n",
       "      <td>-0.112313</td>\n",
       "      <td>-0.219685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>-0.339502</td>\n",
       "      <td>-0.381897</td>\n",
       "      <td>-0.230955</td>\n",
       "      <td>-0.388817</td>\n",
       "      <td>-0.129051</td>\n",
       "      <td>-0.194828</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>-0.155185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566467</td>\n",
       "      <td>0.689533</td>\n",
       "      <td>-0.123068</td>\n",
       "      <td>-0.242940</td>\n",
       "      <td>-0.120815</td>\n",
       "      <td>-0.120243</td>\n",
       "      <td>-0.195707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253813</td>\n",
       "      <td>-0.409700</td>\n",
       "      <td>-0.423276</td>\n",
       "      <td>-0.189843</td>\n",
       "      <td>-0.471080</td>\n",
       "      <td>-0.089120</td>\n",
       "      <td>-0.125862</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>-0.118202</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.503536</td>\n",
       "      <td>-0.125102</td>\n",
       "      <td>-0.325876</td>\n",
       "      <td>-0.165923</td>\n",
       "      <td>-0.163526</td>\n",
       "      <td>-0.373768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325998</td>\n",
       "      <td>-0.394384</td>\n",
       "      <td>-0.426724</td>\n",
       "      <td>-0.280532</td>\n",
       "      <td>-0.429949</td>\n",
       "      <td>-0.267361</td>\n",
       "      <td>-0.270690</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.375635</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.623070</td>\n",
       "      <td>0.604314</td>\n",
       "      <td>-0.554719</td>\n",
       "      <td>-0.774413</td>\n",
       "      <td>-0.699870</td>\n",
       "      <td>-0.696082</td>\n",
       "      <td>-0.856534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756439</td>\n",
       "      <td>-0.275048</td>\n",
       "      <td>-0.325862</td>\n",
       "      <td>-0.108827</td>\n",
       "      <td>-0.367609</td>\n",
       "      <td>-0.175926</td>\n",
       "      <td>-0.257328</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>-0.480058</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.500429</td>\n",
       "      <td>0.667963</td>\n",
       "      <td>-0.544752</td>\n",
       "      <td>-0.669360</td>\n",
       "      <td>-0.655506</td>\n",
       "      <td>-0.654384</td>\n",
       "      <td>-0.567533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.686172</td>\n",
       "      <td>-0.526484</td>\n",
       "      <td>-0.551293</td>\n",
       "      <td>-0.480048</td>\n",
       "      <td>-0.508997</td>\n",
       "      <td>-0.501157</td>\n",
       "      <td>-0.485345</td>\n",
       "      <td>-0.556951</td>\n",
       "      <td>-0.253082</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips_  year_  week_num_  PRECTOT_mean   PS_mean  QV2M_mean  T2M_mean  \\\n",
       "0   1001   2000          1      1.078902  0.591231  -0.067941 -0.230095   \n",
       "1   1001   2000          2      0.566467  0.689533  -0.123068 -0.242940   \n",
       "2   1001   2000          3      0.705403  0.503536  -0.125102 -0.325876   \n",
       "3   1001   2000          4      0.623070  0.604314  -0.554719 -0.774413   \n",
       "4   1001   2000          5     -0.500429  0.667963  -0.544752 -0.669360   \n",
       "\n",
       "   T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...   TS_mean  WS10M_mean  \\\n",
       "0    -0.112909    -0.112313     -0.219685  ... -0.255814   -0.339502   \n",
       "1    -0.120815    -0.120243     -0.195707  ... -0.253813   -0.409700   \n",
       "2    -0.165923    -0.163526     -0.373768  ... -0.325998   -0.394384   \n",
       "3    -0.699870    -0.696082     -0.856534  ... -0.756439   -0.275048   \n",
       "4    -0.655506    -0.654384     -0.567533  ... -0.686172   -0.526484   \n",
       "\n",
       "   WS10M_MAX_mean  WS10M_MIN_mean  WS10M_RANGE_mean  WS50M_mean  \\\n",
       "0       -0.381897       -0.230955         -0.388817   -0.129051   \n",
       "1       -0.423276       -0.189843         -0.471080   -0.089120   \n",
       "2       -0.426724       -0.280532         -0.429949   -0.267361   \n",
       "3       -0.325862       -0.108827         -0.367609   -0.175926   \n",
       "4       -0.551293       -0.480048         -0.508997   -0.501157   \n",
       "\n",
       "   WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  score_max  \n",
       "0       -0.194828       -0.105528         -0.155185        1.0  \n",
       "1       -0.125862       -0.015913         -0.118202        2.0  \n",
       "2       -0.270690        0.000838         -0.375635        2.0  \n",
       "3       -0.257328        0.145729         -0.480058        2.0  \n",
       "4       -0.485345       -0.556951         -0.253082        1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef39760d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.046286</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.078902</td>\n",
       "      <td>0.591231</td>\n",
       "      <td>-0.067941</td>\n",
       "      <td>-0.230095</td>\n",
       "      <td>-0.112909</td>\n",
       "      <td>-0.112313</td>\n",
       "      <td>-0.219685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255814</td>\n",
       "      <td>-0.339502</td>\n",
       "      <td>-0.381897</td>\n",
       "      <td>-0.230955</td>\n",
       "      <td>-0.388817</td>\n",
       "      <td>-0.129051</td>\n",
       "      <td>-0.194828</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>-0.155185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.046286</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.961538</td>\n",
       "      <td>0.566467</td>\n",
       "      <td>0.689533</td>\n",
       "      <td>-0.123068</td>\n",
       "      <td>-0.242940</td>\n",
       "      <td>-0.120815</td>\n",
       "      <td>-0.120243</td>\n",
       "      <td>-0.195707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253813</td>\n",
       "      <td>-0.409700</td>\n",
       "      <td>-0.423276</td>\n",
       "      <td>-0.189843</td>\n",
       "      <td>-0.471080</td>\n",
       "      <td>-0.089120</td>\n",
       "      <td>-0.125862</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>-0.118202</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.046286</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.503536</td>\n",
       "      <td>-0.125102</td>\n",
       "      <td>-0.325876</td>\n",
       "      <td>-0.165923</td>\n",
       "      <td>-0.163526</td>\n",
       "      <td>-0.373768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325998</td>\n",
       "      <td>-0.394384</td>\n",
       "      <td>-0.426724</td>\n",
       "      <td>-0.280532</td>\n",
       "      <td>-0.429949</td>\n",
       "      <td>-0.267361</td>\n",
       "      <td>-0.270690</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.375635</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.046286</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.884615</td>\n",
       "      <td>0.623070</td>\n",
       "      <td>0.604314</td>\n",
       "      <td>-0.554719</td>\n",
       "      <td>-0.774413</td>\n",
       "      <td>-0.699870</td>\n",
       "      <td>-0.696082</td>\n",
       "      <td>-0.856534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756439</td>\n",
       "      <td>-0.275048</td>\n",
       "      <td>-0.325862</td>\n",
       "      <td>-0.108827</td>\n",
       "      <td>-0.367609</td>\n",
       "      <td>-0.175926</td>\n",
       "      <td>-0.257328</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>-0.480058</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.046286</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>-0.500429</td>\n",
       "      <td>0.667963</td>\n",
       "      <td>-0.544752</td>\n",
       "      <td>-0.669360</td>\n",
       "      <td>-0.655506</td>\n",
       "      <td>-0.654384</td>\n",
       "      <td>-0.567533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.686172</td>\n",
       "      <td>-0.526484</td>\n",
       "      <td>-0.551293</td>\n",
       "      <td>-0.480048</td>\n",
       "      <td>-0.508997</td>\n",
       "      <td>-0.501157</td>\n",
       "      <td>-0.485345</td>\n",
       "      <td>-0.556951</td>\n",
       "      <td>-0.253082</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756791</th>\n",
       "      <td>0.995104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>-0.436964</td>\n",
       "      <td>-3.910184</td>\n",
       "      <td>-0.669650</td>\n",
       "      <td>-1.029177</td>\n",
       "      <td>-1.075056</td>\n",
       "      <td>-1.070989</td>\n",
       "      <td>-1.155751</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.043844</td>\n",
       "      <td>0.373963</td>\n",
       "      <td>0.383621</td>\n",
       "      <td>0.342201</td>\n",
       "      <td>0.446015</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.376293</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.362582</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756792</th>\n",
       "      <td>0.995104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>-0.313036</td>\n",
       "      <td>-3.843352</td>\n",
       "      <td>-0.730065</td>\n",
       "      <td>-1.298996</td>\n",
       "      <td>-1.317057</td>\n",
       "      <td>-1.298974</td>\n",
       "      <td>-1.369863</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.303409</td>\n",
       "      <td>-0.054244</td>\n",
       "      <td>0.060776</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>0.287275</td>\n",
       "      <td>-0.234375</td>\n",
       "      <td>-0.126293</td>\n",
       "      <td>-0.391122</td>\n",
       "      <td>0.205946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756793</th>\n",
       "      <td>0.995104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>-0.274014</td>\n",
       "      <td>-3.888967</td>\n",
       "      <td>-0.768104</td>\n",
       "      <td>-1.431524</td>\n",
       "      <td>-1.437965</td>\n",
       "      <td>-1.414552</td>\n",
       "      <td>-1.427528</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.459448</td>\n",
       "      <td>-0.079132</td>\n",
       "      <td>0.188362</td>\n",
       "      <td>-0.627570</td>\n",
       "      <td>0.672879</td>\n",
       "      <td>-0.309028</td>\n",
       "      <td>-0.016810</td>\n",
       "      <td>-0.838358</td>\n",
       "      <td>0.777375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756794</th>\n",
       "      <td>0.995104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>-0.267581</td>\n",
       "      <td>-3.854314</td>\n",
       "      <td>-0.678804</td>\n",
       "      <td>-1.158727</td>\n",
       "      <td>-1.129371</td>\n",
       "      <td>-1.124160</td>\n",
       "      <td>-1.150347</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.230224</td>\n",
       "      <td>0.559030</td>\n",
       "      <td>0.505603</td>\n",
       "      <td>0.509069</td>\n",
       "      <td>0.541131</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.590948</td>\n",
       "      <td>0.652429</td>\n",
       "      <td>0.509065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756795</th>\n",
       "      <td>0.995104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>-0.402373</td>\n",
       "      <td>-3.804279</td>\n",
       "      <td>-0.743084</td>\n",
       "      <td>-1.253870</td>\n",
       "      <td>-1.283064</td>\n",
       "      <td>-1.269574</td>\n",
       "      <td>-1.205522</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.341308</td>\n",
       "      <td>0.536056</td>\n",
       "      <td>0.519899</td>\n",
       "      <td>0.580210</td>\n",
       "      <td>0.526028</td>\n",
       "      <td>0.593654</td>\n",
       "      <td>0.583836</td>\n",
       "      <td>0.630793</td>\n",
       "      <td>0.516558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756796 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2         3         4         5         6   \\\n",
       "0       -1.046286 -1.0 -1.000000  1.078902  0.591231 -0.067941 -0.230095   \n",
       "1       -1.046286 -1.0 -0.961538  0.566467  0.689533 -0.123068 -0.242940   \n",
       "2       -1.046286 -1.0 -0.923077  0.705403  0.503536 -0.125102 -0.325876   \n",
       "3       -1.046286 -1.0 -0.884615  0.623070  0.604314 -0.554719 -0.774413   \n",
       "4       -1.046286 -1.0 -0.846154 -0.500429  0.667963 -0.544752 -0.669360   \n",
       "...           ...  ...       ...       ...       ...       ...       ...   \n",
       "2756791  0.995104  1.0  0.807692 -0.436964 -3.910184 -0.669650 -1.029177   \n",
       "2756792  0.995104  1.0  0.846154 -0.313036 -3.843352 -0.730065 -1.298996   \n",
       "2756793  0.995104  1.0  0.884615 -0.274014 -3.888967 -0.768104 -1.431524   \n",
       "2756794  0.995104  1.0  0.923077 -0.267581 -3.854314 -0.678804 -1.158727   \n",
       "2756795  0.995104  1.0  0.961538 -0.402373 -3.804279 -0.743084 -1.253870   \n",
       "\n",
       "               7         8         9   ...        12        13        14  \\\n",
       "0       -0.112909 -0.112313 -0.219685  ... -0.255814 -0.339502 -0.381897   \n",
       "1       -0.120815 -0.120243 -0.195707  ... -0.253813 -0.409700 -0.423276   \n",
       "2       -0.165923 -0.163526 -0.373768  ... -0.325998 -0.394384 -0.426724   \n",
       "3       -0.699870 -0.696082 -0.856534  ... -0.756439 -0.275048 -0.325862   \n",
       "4       -0.655506 -0.654384 -0.567533  ... -0.686172 -0.526484 -0.551293   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "2756791 -1.075056 -1.070989 -1.155751  ... -1.043844  0.373963  0.383621   \n",
       "2756792 -1.317057 -1.298974 -1.369863  ... -1.303409 -0.054244  0.060776   \n",
       "2756793 -1.437965 -1.414552 -1.427528  ... -1.459448 -0.079132  0.188362   \n",
       "2756794 -1.129371 -1.124160 -1.150347  ... -1.230224  0.559030  0.505603   \n",
       "2756795 -1.283064 -1.269574 -1.205522  ... -1.341308  0.536056  0.519899   \n",
       "\n",
       "               15        16        17        18        19        20   21  \n",
       "0       -0.230955 -0.388817 -0.129051 -0.194828 -0.105528 -0.155185  1.0  \n",
       "1       -0.189843 -0.471080 -0.089120 -0.125862 -0.015913 -0.118202  2.0  \n",
       "2       -0.280532 -0.429949 -0.267361 -0.270690  0.000838 -0.375635  2.0  \n",
       "3       -0.108827 -0.367609 -0.175926 -0.257328  0.145729 -0.480058  2.0  \n",
       "4       -0.480048 -0.508997 -0.501157 -0.485345 -0.556951 -0.253082  1.0  \n",
       "...           ...       ...       ...       ...       ...       ...  ...  \n",
       "2756791  0.342201  0.446015  0.351852  0.376293  0.405360  0.362582  0.0  \n",
       "2756792 -0.259976  0.287275 -0.234375 -0.126293 -0.391122  0.205946  0.0  \n",
       "2756793 -0.627570  0.672879 -0.309028 -0.016810 -0.838358  0.777375  0.0  \n",
       "2756794  0.509069  0.541131  0.625000  0.590948  0.652429  0.509065  0.0  \n",
       "2756795  0.580210  0.526028  0.593654  0.583836  0.630793  0.516558  0.0  \n",
       "\n",
       "[2756796 rows x 22 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e4ffc",
   "metadata": {},
   "source": [
    "### Manual coding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subsample_sequence(df, length):\n",
    "    df_sample = df.sample(length)\n",
    "    X_sample = df_sample.iloc[:-1].copy()\n",
    "    y_sample = float(df_sample[['score_max']].iloc[-1])\n",
    "    \n",
    "    return X_sample, y_sample\n",
    "\n",
    "def get_X_y(df, n_sequences, length):\n",
    "    X = [split_subsample_sequence(df, length)[0] for n in range(n_sequences)]\n",
    "    y = [split_subsample_sequence(df, length)[1] for n in range(n_sequences)]\n",
    "    \n",
    "    \n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5417a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df984cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_X_y(d, 2000, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ab5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subsample_sequence(df, length):\n",
    "    df_sample = df.sample(length,random_state=1)\n",
    "    X_sample = df_sample.iloc[:-1].copy()\n",
    "    y_sample = float(df_sample[['score_max']].iloc[-1])\n",
    "    \n",
    "    return X_sample, y_sample\n",
    "\n",
    "def get_X_y(df, n_sequences,length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for n in range(n_sequences):\n",
    "        sequence = split_subsample_sequence(df, length)\n",
    "        X.append(sequence[0])\n",
    "        y.append(sequence[1])\n",
    "    \n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def get_X_y_by_geolocation(df, n_sequences, length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for fip in sorted(set(df['fips_'])):\n",
    "        fip_df = df[df['fips_'] == fip]\n",
    "        sequences = get_X_y(fip_df,n_sequences,length)\n",
    "        X.append(sequences[0])\n",
    "        y.append(sequences[1])\n",
    "        \n",
    "\n",
    "    return np.array(X),np.array(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droughts",
   "language": "python",
   "name": "droughts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
