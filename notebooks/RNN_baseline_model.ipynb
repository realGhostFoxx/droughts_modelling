{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "804ef6f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from droughts_modelling.data import DataFunctions\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1efa360",
   "metadata": {},
   "source": [
    "1. Sort out data file\n",
    "2. Check deep learning trainer 2 works - run the evaluate method as this will also train the model\n",
    "3. Hook the trainings up to GCP and iterate over to get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b51fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = DataFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "889d110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_class.light_weekly_aggregate_train()\n",
    "val_data = data_class.light_weekly_aggregate_validate()\n",
    "test_data = data_class.light_weekly_aggregate_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4c6823e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>TS_mean</th>\n",
       "      <th>WS10M_mean</th>\n",
       "      <th>WS10M_MAX_mean</th>\n",
       "      <th>WS10M_MIN_mean</th>\n",
       "      <th>WS10M_RANGE_mean</th>\n",
       "      <th>WS50M_mean</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1.604286</td>\n",
       "      <td>100.710000</td>\n",
       "      <td>5.791429</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>5.324286</td>\n",
       "      <td>5.141429</td>\n",
       "      <td>13.990000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.744286</td>\n",
       "      <td>2.435714</td>\n",
       "      <td>3.325714</td>\n",
       "      <td>1.715714</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>4.891429</td>\n",
       "      <td>6.487143</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>3.147143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>4.114286</td>\n",
       "      <td>100.555714</td>\n",
       "      <td>5.581429</td>\n",
       "      <td>6.798571</td>\n",
       "      <td>4.468571</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>11.945714</td>\n",
       "      <td>...</td>\n",
       "      <td>6.407143</td>\n",
       "      <td>2.378571</td>\n",
       "      <td>3.431429</td>\n",
       "      <td>1.347143</td>\n",
       "      <td>2.087143</td>\n",
       "      <td>4.317143</td>\n",
       "      <td>6.152857</td>\n",
       "      <td>2.728571</td>\n",
       "      <td>3.425714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>100.705714</td>\n",
       "      <td>4.538571</td>\n",
       "      <td>4.972857</td>\n",
       "      <td>1.648571</td>\n",
       "      <td>1.458571</td>\n",
       "      <td>11.154286</td>\n",
       "      <td>...</td>\n",
       "      <td>4.422857</td>\n",
       "      <td>2.618571</td>\n",
       "      <td>3.755714</td>\n",
       "      <td>1.561429</td>\n",
       "      <td>2.192857</td>\n",
       "      <td>4.744286</td>\n",
       "      <td>7.060000</td>\n",
       "      <td>2.927143</td>\n",
       "      <td>4.135714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>100.631429</td>\n",
       "      <td>5.165714</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.421429</td>\n",
       "      <td>3.234286</td>\n",
       "      <td>13.391429</td>\n",
       "      <td>...</td>\n",
       "      <td>6.021429</td>\n",
       "      <td>1.984286</td>\n",
       "      <td>2.894286</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>1.898571</td>\n",
       "      <td>3.995714</td>\n",
       "      <td>6.041429</td>\n",
       "      <td>1.671429</td>\n",
       "      <td>4.368571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.574286</td>\n",
       "      <td>100.781429</td>\n",
       "      <td>8.638571</td>\n",
       "      <td>13.088571</td>\n",
       "      <td>10.671429</td>\n",
       "      <td>10.484286</td>\n",
       "      <td>18.827143</td>\n",
       "      <td>...</td>\n",
       "      <td>13.062857</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>3.352857</td>\n",
       "      <td>1.805714</td>\n",
       "      <td>1.545714</td>\n",
       "      <td>5.032857</td>\n",
       "      <td>6.378571</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>2.965714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326334</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>49</td>\n",
       "      <td>0.198571</td>\n",
       "      <td>83.754286</td>\n",
       "      <td>1.977143</td>\n",
       "      <td>-2.270000</td>\n",
       "      <td>-11.144286</td>\n",
       "      <td>-6.707143</td>\n",
       "      <td>3.998571</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.080000</td>\n",
       "      <td>2.752857</td>\n",
       "      <td>3.825714</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>2.098571</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>5.825714</td>\n",
       "      <td>2.747143</td>\n",
       "      <td>3.077143</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326335</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>50</td>\n",
       "      <td>0.538571</td>\n",
       "      <td>83.165714</td>\n",
       "      <td>2.172857</td>\n",
       "      <td>-2.527143</td>\n",
       "      <td>-10.194286</td>\n",
       "      <td>-6.361429</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.081429</td>\n",
       "      <td>2.917143</td>\n",
       "      <td>4.511429</td>\n",
       "      <td>1.295714</td>\n",
       "      <td>3.215714</td>\n",
       "      <td>4.381429</td>\n",
       "      <td>6.402857</td>\n",
       "      <td>2.027143</td>\n",
       "      <td>4.378571</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326336</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>51</td>\n",
       "      <td>1.041429</td>\n",
       "      <td>82.821429</td>\n",
       "      <td>2.427143</td>\n",
       "      <td>-3.722857</td>\n",
       "      <td>-8.595714</td>\n",
       "      <td>-6.158571</td>\n",
       "      <td>1.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.297143</td>\n",
       "      <td>3.715714</td>\n",
       "      <td>5.474286</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>3.242857</td>\n",
       "      <td>5.808571</td>\n",
       "      <td>8.092857</td>\n",
       "      <td>3.615714</td>\n",
       "      <td>4.475714</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326337</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>52</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>82.907143</td>\n",
       "      <td>2.564286</td>\n",
       "      <td>-2.982857</td>\n",
       "      <td>-8.382857</td>\n",
       "      <td>-5.681429</td>\n",
       "      <td>2.851429</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.315714</td>\n",
       "      <td>5.145714</td>\n",
       "      <td>7.682857</td>\n",
       "      <td>3.452857</td>\n",
       "      <td>4.227143</td>\n",
       "      <td>7.677143</td>\n",
       "      <td>10.792857</td>\n",
       "      <td>5.254286</td>\n",
       "      <td>5.537143</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326338</th>\n",
       "      <td>56043</td>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>82.877500</td>\n",
       "      <td>1.847500</td>\n",
       "      <td>-6.230000</td>\n",
       "      <td>-11.977500</td>\n",
       "      <td>-9.105000</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.192500</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>4.212500</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>3.662500</td>\n",
       "      <td>3.542500</td>\n",
       "      <td>5.965000</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326339 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fips_  year_  week_num_  PRECTOT_mean     PS_mean  QV2M_mean  \\\n",
       "0        1001   2019          2      1.604286  100.710000   5.791429   \n",
       "1        1001   2019          3      4.114286  100.555714   5.581429   \n",
       "2        1001   2019          4      7.530000  100.705714   4.538571   \n",
       "3        1001   2019          5      0.878571  100.631429   5.165714   \n",
       "4        1001   2019          6      0.574286  100.781429   8.638571   \n",
       "...       ...    ...        ...           ...         ...        ...   \n",
       "326334  56043   2020         49      0.198571   83.754286   1.977143   \n",
       "326335  56043   2020         50      0.538571   83.165714   2.172857   \n",
       "326336  56043   2020         51      1.041429   82.821429   2.427143   \n",
       "326337  56043   2020         52      0.990000   82.907143   2.564286   \n",
       "326338  56043   2020         53      0.002500   82.877500   1.847500   \n",
       "\n",
       "         T2M_mean  T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...    TS_mean  \\\n",
       "0        7.820000     5.324286     5.141429     13.990000  ...   7.744286   \n",
       "1        6.798571     4.468571     4.340000     11.945714  ...   6.407143   \n",
       "2        4.972857     1.648571     1.458571     11.154286  ...   4.422857   \n",
       "3        6.250000     3.421429     3.234286     13.391429  ...   6.021429   \n",
       "4       13.088571    10.671429    10.484286     18.827143  ...  13.062857   \n",
       "...           ...          ...          ...           ...  ...        ...   \n",
       "326334  -2.270000   -11.144286    -6.707143      3.998571  ...  -4.080000   \n",
       "326335  -2.527143   -10.194286    -6.361429      2.264286  ...  -4.081429   \n",
       "326336  -3.722857    -8.595714    -6.158571      1.544286  ...  -5.297143   \n",
       "326337  -2.982857    -8.382857    -5.681429      2.851429  ...  -4.315714   \n",
       "326338  -6.230000   -11.977500    -9.105000      0.282500  ...  -9.192500   \n",
       "\n",
       "        WS10M_mean  WS10M_MAX_mean  WS10M_MIN_mean  WS10M_RANGE_mean  \\\n",
       "0         2.435714        3.325714        1.715714          1.610000   \n",
       "1         2.378571        3.431429        1.347143          2.087143   \n",
       "2         2.618571        3.755714        1.561429          2.192857   \n",
       "3         1.984286        2.894286        0.992857          1.898571   \n",
       "4         2.570000        3.352857        1.805714          1.545714   \n",
       "...            ...             ...             ...               ...   \n",
       "326334    2.752857        3.825714        1.730000          2.098571   \n",
       "326335    2.917143        4.511429        1.295714          3.215714   \n",
       "326336    3.715714        5.474286        2.230000          3.242857   \n",
       "326337    5.145714        7.682857        3.452857          4.227143   \n",
       "326338    2.405000        4.212500        0.552500          3.662500   \n",
       "\n",
       "        WS50M_mean  WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  \\\n",
       "0         4.891429        6.487143        3.340000          3.147143   \n",
       "1         4.317143        6.152857        2.728571          3.425714   \n",
       "2         4.744286        7.060000        2.927143          4.135714   \n",
       "3         3.995714        6.041429        1.671429          4.368571   \n",
       "4         5.032857        6.378571        3.410000          2.965714   \n",
       "...            ...             ...             ...               ...   \n",
       "326334    4.190000        5.825714        2.747143          3.077143   \n",
       "326335    4.381429        6.402857        2.027143          4.378571   \n",
       "326336    5.808571        8.092857        3.615714          4.475714   \n",
       "326337    7.677143       10.792857        5.254286          5.537143   \n",
       "326338    3.542500        5.965000        0.907500          5.062500   \n",
       "\n",
       "        score_max  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "326334        4.0  \n",
       "326335        4.0  \n",
       "326336        4.0  \n",
       "326337        4.0  \n",
       "326338        4.0  \n",
       "\n",
       "[326339 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e831bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bee54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(df[['score_max']])\n",
    "scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "scaled_test_data_ohe = df.drop(columns=['score_max']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f3b0373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 326339)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoremax_encoded.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0be84f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataPreprocessing():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.test_data = test_data.copy()\n",
    "        self.features = self.test_data.drop(columns=['fips_','year_','week_num_','score_max']).columns\n",
    "        \n",
    "    def test_robust(self):\n",
    "        df = self.test_data.copy()\n",
    "        for f in self.features:\n",
    "            median = np.median(df[f])\n",
    "            iqr = np.subtract(*np.percentile(df[f], [75, 25]))\n",
    "            df[f] = df[f].map(lambda x: (x-median)/iqr)\n",
    "        \n",
    "        self.test_scaled_data = df\n",
    "    \n",
    "    def test_ohe(self):\n",
    "        self.test_robust()\n",
    "        df = self.test_scaled_data.copy()\n",
    "        ohe = OneHotEncoder(sparse = False)\n",
    "        ohe.fit(df[['score_max']])\n",
    "        scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "        df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "        self.scaled_test_data_ohe = df.drop(columns=['score_max']) \n",
    "        \n",
    "    \n",
    "    def test_window(self):\n",
    "        self.test_ohe()\n",
    "        self.test_windowed_data = WindowGenerator(self.scaled_test_data_ohe,input_width=6,label_width=6,shift=1,label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\n",
    "        return self.test_windowed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61b10c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 6, 27), (None, 6, 6)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = TestDataPreprocessing()\n",
    "scaled = c.test_window()\n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc1f83",
   "metadata": {},
   "source": [
    "## Tensorflow window class method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7128a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self,data,input_width,label_width,shift,label_columns=None):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "            self.column_indices = {name: i for i, name in enumerate(self.data.columns)}\n",
    "\n",
    "    \n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    \n",
    "    def split_window(self, list_of_consecutive_inputs_w_labels):\n",
    "        inputs = list_of_consecutive_inputs_w_labels[:, self.input_slice, :]\n",
    "        labels = list_of_consecutive_inputs_w_labels[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns],axis=-1)\n",
    "\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self):\n",
    "        data = np.array(self.data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(data=data,targets=None,\n",
    "                                                              sequence_length=self.total_window_size,\n",
    "          sequence_stride=1,\n",
    "          shuffle=True,\n",
    "          batch_size=32,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17f3bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd47fe15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>WS50M_mean</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max_0</th>\n",
       "      <th>score_max_1</th>\n",
       "      <th>score_max_2</th>\n",
       "      <th>score_max_3</th>\n",
       "      <th>score_max_4</th>\n",
       "      <th>score_max_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.261429</td>\n",
       "      <td>100.702857</td>\n",
       "      <td>6.491429</td>\n",
       "      <td>9.878571</td>\n",
       "      <td>5.648571</td>\n",
       "      <td>5.674286</td>\n",
       "      <td>16.345714</td>\n",
       "      <td>...</td>\n",
       "      <td>5.044286</td>\n",
       "      <td>6.934286</td>\n",
       "      <td>2.815714</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.554286</td>\n",
       "      <td>101.100000</td>\n",
       "      <td>6.104286</td>\n",
       "      <td>9.662857</td>\n",
       "      <td>5.527143</td>\n",
       "      <td>5.552857</td>\n",
       "      <td>16.751429</td>\n",
       "      <td>...</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>7.162857</td>\n",
       "      <td>2.968571</td>\n",
       "      <td>4.192857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.017143</td>\n",
       "      <td>100.348571</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>4.834286</td>\n",
       "      <td>4.890000</td>\n",
       "      <td>13.738571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.702857</td>\n",
       "      <td>6.682857</td>\n",
       "      <td>2.997143</td>\n",
       "      <td>3.685714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.742857</td>\n",
       "      <td>100.755714</td>\n",
       "      <td>3.072857</td>\n",
       "      <td>0.737143</td>\n",
       "      <td>-3.367143</td>\n",
       "      <td>-3.265714</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>6.727143</td>\n",
       "      <td>3.244286</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.012857</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.501429</td>\n",
       "      <td>-2.685714</td>\n",
       "      <td>-2.627143</td>\n",
       "      <td>10.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.125714</td>\n",
       "      <td>5.971429</td>\n",
       "      <td>2.045714</td>\n",
       "      <td>3.927143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759898</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>48</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>82.517143</td>\n",
       "      <td>2.265714</td>\n",
       "      <td>-3.541429</td>\n",
       "      <td>-9.130000</td>\n",
       "      <td>-9.007143</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>...</td>\n",
       "      <td>6.231429</td>\n",
       "      <td>8.827143</td>\n",
       "      <td>3.687143</td>\n",
       "      <td>5.140000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759899</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>49</td>\n",
       "      <td>0.624286</td>\n",
       "      <td>82.787143</td>\n",
       "      <td>1.841429</td>\n",
       "      <td>-8.072857</td>\n",
       "      <td>-12.847143</td>\n",
       "      <td>-12.498571</td>\n",
       "      <td>-3.115714</td>\n",
       "      <td>...</td>\n",
       "      <td>4.784286</td>\n",
       "      <td>7.161429</td>\n",
       "      <td>2.328571</td>\n",
       "      <td>4.831429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759900</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>50</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>82.602857</td>\n",
       "      <td>1.574286</td>\n",
       "      <td>-10.298571</td>\n",
       "      <td>-14.704286</td>\n",
       "      <td>-14.268571</td>\n",
       "      <td>-4.091429</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>7.524286</td>\n",
       "      <td>1.565714</td>\n",
       "      <td>5.957143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759901</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>51</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>82.742857</td>\n",
       "      <td>2.201429</td>\n",
       "      <td>-5.717143</td>\n",
       "      <td>-9.964286</td>\n",
       "      <td>-9.821429</td>\n",
       "      <td>0.598571</td>\n",
       "      <td>...</td>\n",
       "      <td>6.905714</td>\n",
       "      <td>9.538571</td>\n",
       "      <td>4.108571</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759902</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>82.945000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>-7.315000</td>\n",
       "      <td>-12.325000</td>\n",
       "      <td>-12.048333</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.828333</td>\n",
       "      <td>9.515000</td>\n",
       "      <td>4.071667</td>\n",
       "      <td>5.443333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756796 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fips_  year_  week_num_  PRECTOT_mean     PS_mean  QV2M_mean  \\\n",
       "0         1001   2000          1      5.261429  100.702857   6.491429   \n",
       "1         1001   2000          2      3.554286  101.100000   6.104286   \n",
       "2         1001   2000          3      4.017143  100.348571   6.090000   \n",
       "3         1001   2000          4      3.742857  100.755714   3.072857   \n",
       "4         1001   2000          5      0.000000  101.012857   3.142857   \n",
       "...        ...    ...        ...           ...         ...        ...   \n",
       "2759898  56043   2016         48      0.211429   82.517143   2.265714   \n",
       "2759899  56043   2016         49      0.624286   82.787143   1.841429   \n",
       "2759900  56043   2016         50      0.754286   82.602857   1.574286   \n",
       "2759901  56043   2016         51      0.775714   82.742857   2.201429   \n",
       "2759902  56043   2016         52      0.326667   82.945000   1.750000   \n",
       "\n",
       "          T2M_mean  T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...  WS50M_mean  \\\n",
       "0         9.878571     5.648571     5.674286     16.345714  ...    5.044286   \n",
       "1         9.662857     5.527143     5.552857     16.751429  ...    5.142857   \n",
       "2         8.270000     4.834286     4.890000     13.738571  ...    4.702857   \n",
       "3         0.737143    -3.367143    -3.265714      5.570000  ...    4.928571   \n",
       "4         2.501429    -2.685714    -2.627143     10.460000  ...    4.125714   \n",
       "...            ...          ...          ...           ...  ...         ...   \n",
       "2759898  -3.541429    -9.130000    -9.007143      0.507143  ...    6.231429   \n",
       "2759899  -8.072857   -12.847143   -12.498571     -3.115714  ...    4.784286   \n",
       "2759900 -10.298571   -14.704286   -14.268571     -4.091429  ...    4.600000   \n",
       "2759901  -5.717143    -9.964286    -9.821429      0.598571  ...    6.905714   \n",
       "2759902  -7.315000   -12.325000   -12.048333     -0.335000  ...    6.828333   \n",
       "\n",
       "         WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  score_max_0  \\\n",
       "0              6.934286        2.815714          4.120000          0.0   \n",
       "1              7.162857        2.968571          4.192857          0.0   \n",
       "2              6.682857        2.997143          3.685714          0.0   \n",
       "3              6.727143        3.244286          3.480000          0.0   \n",
       "4              5.971429        2.045714          3.927143          0.0   \n",
       "...                 ...             ...               ...          ...   \n",
       "2759898        8.827143        3.687143          5.140000          1.0   \n",
       "2759899        7.161429        2.328571          4.831429          1.0   \n",
       "2759900        7.524286        1.565714          5.957143          1.0   \n",
       "2759901        9.538571        4.108571          5.428571          1.0   \n",
       "2759902        9.515000        4.071667          5.443333          1.0   \n",
       "\n",
       "         score_max_1  score_max_2  score_max_3  score_max_4  score_max_5  \n",
       "0                1.0          0.0          0.0          0.0          0.0  \n",
       "1                0.0          1.0          0.0          0.0          0.0  \n",
       "2                0.0          1.0          0.0          0.0          0.0  \n",
       "3                0.0          1.0          0.0          0.0          0.0  \n",
       "4                1.0          0.0          0.0          0.0          0.0  \n",
       "...              ...          ...          ...          ...          ...  \n",
       "2759898          0.0          0.0          0.0          0.0          0.0  \n",
       "2759899          0.0          0.0          0.0          0.0          0.0  \n",
       "2759900          0.0          0.0          0.0          0.0          0.0  \n",
       "2759901          0.0          0.0          0.0          0.0          0.0  \n",
       "2759902          0.0          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[2756796 rows x 27 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(df[['score_max']])\n",
    "scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "df_ = df.drop(columns=['score_max'])\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc560586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8806fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_pipe = Pipeline([('robust_scaler',RobustScaler())])\n",
    "encoder = Pipeline([('ohe',OneHotEncoder(sparse=False))])\n",
    "preprocessor = ColumnTransformer([('scaling',scaling_pipe,train_data.drop(columns=['fips_','year_','week_num_','score_max']).columns),\n",
    "                                  ('cat_encoder',encoder,['score_max'])],remainder='passthrough')\n",
    "preprocessed_data = preprocessor.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1db9e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c39381f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max</th>\n",
       "      <th>score_max_0</th>\n",
       "      <th>score_max_1</th>\n",
       "      <th>score_max_2</th>\n",
       "      <th>score_max_3</th>\n",
       "      <th>score_max_4</th>\n",
       "      <th>score_max_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.261429</td>\n",
       "      <td>100.702857</td>\n",
       "      <td>6.491429</td>\n",
       "      <td>9.878571</td>\n",
       "      <td>5.648571</td>\n",
       "      <td>5.674286</td>\n",
       "      <td>16.345714</td>\n",
       "      <td>...</td>\n",
       "      <td>6.934286</td>\n",
       "      <td>2.815714</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.554286</td>\n",
       "      <td>101.100000</td>\n",
       "      <td>6.104286</td>\n",
       "      <td>9.662857</td>\n",
       "      <td>5.527143</td>\n",
       "      <td>5.552857</td>\n",
       "      <td>16.751429</td>\n",
       "      <td>...</td>\n",
       "      <td>7.162857</td>\n",
       "      <td>2.968571</td>\n",
       "      <td>4.192857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.017143</td>\n",
       "      <td>100.348571</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>4.834286</td>\n",
       "      <td>4.890000</td>\n",
       "      <td>13.738571</td>\n",
       "      <td>...</td>\n",
       "      <td>6.682857</td>\n",
       "      <td>2.997143</td>\n",
       "      <td>3.685714</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.742857</td>\n",
       "      <td>100.755714</td>\n",
       "      <td>3.072857</td>\n",
       "      <td>0.737143</td>\n",
       "      <td>-3.367143</td>\n",
       "      <td>-3.265714</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.727143</td>\n",
       "      <td>3.244286</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.012857</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.501429</td>\n",
       "      <td>-2.685714</td>\n",
       "      <td>-2.627143</td>\n",
       "      <td>10.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.971429</td>\n",
       "      <td>2.045714</td>\n",
       "      <td>3.927143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759898</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>48</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>82.517143</td>\n",
       "      <td>2.265714</td>\n",
       "      <td>-3.541429</td>\n",
       "      <td>-9.130000</td>\n",
       "      <td>-9.007143</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>...</td>\n",
       "      <td>8.827143</td>\n",
       "      <td>3.687143</td>\n",
       "      <td>5.140000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759899</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>49</td>\n",
       "      <td>0.624286</td>\n",
       "      <td>82.787143</td>\n",
       "      <td>1.841429</td>\n",
       "      <td>-8.072857</td>\n",
       "      <td>-12.847143</td>\n",
       "      <td>-12.498571</td>\n",
       "      <td>-3.115714</td>\n",
       "      <td>...</td>\n",
       "      <td>7.161429</td>\n",
       "      <td>2.328571</td>\n",
       "      <td>4.831429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759900</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>50</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>82.602857</td>\n",
       "      <td>1.574286</td>\n",
       "      <td>-10.298571</td>\n",
       "      <td>-14.704286</td>\n",
       "      <td>-14.268571</td>\n",
       "      <td>-4.091429</td>\n",
       "      <td>...</td>\n",
       "      <td>7.524286</td>\n",
       "      <td>1.565714</td>\n",
       "      <td>5.957143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759901</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>51</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>82.742857</td>\n",
       "      <td>2.201429</td>\n",
       "      <td>-5.717143</td>\n",
       "      <td>-9.964286</td>\n",
       "      <td>-9.821429</td>\n",
       "      <td>0.598571</td>\n",
       "      <td>...</td>\n",
       "      <td>9.538571</td>\n",
       "      <td>4.108571</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759902</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>82.945000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>-7.315000</td>\n",
       "      <td>-12.325000</td>\n",
       "      <td>-12.048333</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.515000</td>\n",
       "      <td>4.071667</td>\n",
       "      <td>5.443333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756796 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fips_  year_  week_num_  PRECTOT_mean     PS_mean  QV2M_mean  \\\n",
       "0         1001   2000          1      5.261429  100.702857   6.491429   \n",
       "1         1001   2000          2      3.554286  101.100000   6.104286   \n",
       "2         1001   2000          3      4.017143  100.348571   6.090000   \n",
       "3         1001   2000          4      3.742857  100.755714   3.072857   \n",
       "4         1001   2000          5      0.000000  101.012857   3.142857   \n",
       "...        ...    ...        ...           ...         ...        ...   \n",
       "2759898  56043   2016         48      0.211429   82.517143   2.265714   \n",
       "2759899  56043   2016         49      0.624286   82.787143   1.841429   \n",
       "2759900  56043   2016         50      0.754286   82.602857   1.574286   \n",
       "2759901  56043   2016         51      0.775714   82.742857   2.201429   \n",
       "2759902  56043   2016         52      0.326667   82.945000   1.750000   \n",
       "\n",
       "          T2M_mean  T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...  \\\n",
       "0         9.878571     5.648571     5.674286     16.345714  ...   \n",
       "1         9.662857     5.527143     5.552857     16.751429  ...   \n",
       "2         8.270000     4.834286     4.890000     13.738571  ...   \n",
       "3         0.737143    -3.367143    -3.265714      5.570000  ...   \n",
       "4         2.501429    -2.685714    -2.627143     10.460000  ...   \n",
       "...            ...          ...          ...           ...  ...   \n",
       "2759898  -3.541429    -9.130000    -9.007143      0.507143  ...   \n",
       "2759899  -8.072857   -12.847143   -12.498571     -3.115714  ...   \n",
       "2759900 -10.298571   -14.704286   -14.268571     -4.091429  ...   \n",
       "2759901  -5.717143    -9.964286    -9.821429      0.598571  ...   \n",
       "2759902  -7.315000   -12.325000   -12.048333     -0.335000  ...   \n",
       "\n",
       "         WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  score_max  \\\n",
       "0              6.934286        2.815714          4.120000        1.0   \n",
       "1              7.162857        2.968571          4.192857        2.0   \n",
       "2              6.682857        2.997143          3.685714        2.0   \n",
       "3              6.727143        3.244286          3.480000        2.0   \n",
       "4              5.971429        2.045714          3.927143        1.0   \n",
       "...                 ...             ...               ...        ...   \n",
       "2759898        8.827143        3.687143          5.140000        0.0   \n",
       "2759899        7.161429        2.328571          4.831429        0.0   \n",
       "2759900        7.524286        1.565714          5.957143        0.0   \n",
       "2759901        9.538571        4.108571          5.428571        0.0   \n",
       "2759902        9.515000        4.071667          5.443333        0.0   \n",
       "\n",
       "         score_max_0  score_max_1  score_max_2  score_max_3  score_max_4  \\\n",
       "0                0.0          1.0          0.0          0.0          0.0   \n",
       "1                0.0          0.0          1.0          0.0          0.0   \n",
       "2                0.0          0.0          1.0          0.0          0.0   \n",
       "3                0.0          0.0          1.0          0.0          0.0   \n",
       "4                0.0          1.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2759898          1.0          0.0          0.0          0.0          0.0   \n",
       "2759899          1.0          0.0          0.0          0.0          0.0   \n",
       "2759900          1.0          0.0          0.0          0.0          0.0   \n",
       "2759901          1.0          0.0          0.0          0.0          0.0   \n",
       "2759902          1.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "         score_max_5  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "2759898          0.0  \n",
       "2759899          0.0  \n",
       "2759900          0.0  \n",
       "2759901          0.0  \n",
       "2759902          0.0  \n",
       "\n",
       "[2756796 rows x 28 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c1b18c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_</th>\n",
       "      <th>year_</th>\n",
       "      <th>week_num_</th>\n",
       "      <th>PRECTOT_mean</th>\n",
       "      <th>PS_mean</th>\n",
       "      <th>QV2M_mean</th>\n",
       "      <th>T2M_mean</th>\n",
       "      <th>T2MDEW_mean</th>\n",
       "      <th>T2MWET_mean</th>\n",
       "      <th>T2M_MAX_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>WS50M_mean</th>\n",
       "      <th>WS50M_MAX_mean</th>\n",
       "      <th>WS50M_MIN_mean</th>\n",
       "      <th>WS50M_RANGE_mean</th>\n",
       "      <th>score_max_0</th>\n",
       "      <th>score_max_1</th>\n",
       "      <th>score_max_2</th>\n",
       "      <th>score_max_3</th>\n",
       "      <th>score_max_4</th>\n",
       "      <th>score_max_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.261429</td>\n",
       "      <td>100.702857</td>\n",
       "      <td>6.491429</td>\n",
       "      <td>9.878571</td>\n",
       "      <td>5.648571</td>\n",
       "      <td>5.674286</td>\n",
       "      <td>16.345714</td>\n",
       "      <td>...</td>\n",
       "      <td>5.044286</td>\n",
       "      <td>6.934286</td>\n",
       "      <td>2.815714</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.554286</td>\n",
       "      <td>101.100000</td>\n",
       "      <td>6.104286</td>\n",
       "      <td>9.662857</td>\n",
       "      <td>5.527143</td>\n",
       "      <td>5.552857</td>\n",
       "      <td>16.751429</td>\n",
       "      <td>...</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>7.162857</td>\n",
       "      <td>2.968571</td>\n",
       "      <td>4.192857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4.017143</td>\n",
       "      <td>100.348571</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>4.834286</td>\n",
       "      <td>4.890000</td>\n",
       "      <td>13.738571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.702857</td>\n",
       "      <td>6.682857</td>\n",
       "      <td>2.997143</td>\n",
       "      <td>3.685714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.742857</td>\n",
       "      <td>100.755714</td>\n",
       "      <td>3.072857</td>\n",
       "      <td>0.737143</td>\n",
       "      <td>-3.367143</td>\n",
       "      <td>-3.265714</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>6.727143</td>\n",
       "      <td>3.244286</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.012857</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.501429</td>\n",
       "      <td>-2.685714</td>\n",
       "      <td>-2.627143</td>\n",
       "      <td>10.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.125714</td>\n",
       "      <td>5.971429</td>\n",
       "      <td>2.045714</td>\n",
       "      <td>3.927143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759898</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>48</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>82.517143</td>\n",
       "      <td>2.265714</td>\n",
       "      <td>-3.541429</td>\n",
       "      <td>-9.130000</td>\n",
       "      <td>-9.007143</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>...</td>\n",
       "      <td>6.231429</td>\n",
       "      <td>8.827143</td>\n",
       "      <td>3.687143</td>\n",
       "      <td>5.140000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759899</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>49</td>\n",
       "      <td>0.624286</td>\n",
       "      <td>82.787143</td>\n",
       "      <td>1.841429</td>\n",
       "      <td>-8.072857</td>\n",
       "      <td>-12.847143</td>\n",
       "      <td>-12.498571</td>\n",
       "      <td>-3.115714</td>\n",
       "      <td>...</td>\n",
       "      <td>4.784286</td>\n",
       "      <td>7.161429</td>\n",
       "      <td>2.328571</td>\n",
       "      <td>4.831429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759900</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>50</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>82.602857</td>\n",
       "      <td>1.574286</td>\n",
       "      <td>-10.298571</td>\n",
       "      <td>-14.704286</td>\n",
       "      <td>-14.268571</td>\n",
       "      <td>-4.091429</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>7.524286</td>\n",
       "      <td>1.565714</td>\n",
       "      <td>5.957143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759901</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>51</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>82.742857</td>\n",
       "      <td>2.201429</td>\n",
       "      <td>-5.717143</td>\n",
       "      <td>-9.964286</td>\n",
       "      <td>-9.821429</td>\n",
       "      <td>0.598571</td>\n",
       "      <td>...</td>\n",
       "      <td>6.905714</td>\n",
       "      <td>9.538571</td>\n",
       "      <td>4.108571</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759902</th>\n",
       "      <td>56043</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>82.945000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>-7.315000</td>\n",
       "      <td>-12.325000</td>\n",
       "      <td>-12.048333</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.828333</td>\n",
       "      <td>9.515000</td>\n",
       "      <td>4.071667</td>\n",
       "      <td>5.443333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756796 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fips_  year_  week_num_  PRECTOT_mean     PS_mean  QV2M_mean  \\\n",
       "0         1001   2000          1      5.261429  100.702857   6.491429   \n",
       "1         1001   2000          2      3.554286  101.100000   6.104286   \n",
       "2         1001   2000          3      4.017143  100.348571   6.090000   \n",
       "3         1001   2000          4      3.742857  100.755714   3.072857   \n",
       "4         1001   2000          5      0.000000  101.012857   3.142857   \n",
       "...        ...    ...        ...           ...         ...        ...   \n",
       "2759898  56043   2016         48      0.211429   82.517143   2.265714   \n",
       "2759899  56043   2016         49      0.624286   82.787143   1.841429   \n",
       "2759900  56043   2016         50      0.754286   82.602857   1.574286   \n",
       "2759901  56043   2016         51      0.775714   82.742857   2.201429   \n",
       "2759902  56043   2016         52      0.326667   82.945000   1.750000   \n",
       "\n",
       "          T2M_mean  T2MDEW_mean  T2MWET_mean  T2M_MAX_mean  ...  WS50M_mean  \\\n",
       "0         9.878571     5.648571     5.674286     16.345714  ...    5.044286   \n",
       "1         9.662857     5.527143     5.552857     16.751429  ...    5.142857   \n",
       "2         8.270000     4.834286     4.890000     13.738571  ...    4.702857   \n",
       "3         0.737143    -3.367143    -3.265714      5.570000  ...    4.928571   \n",
       "4         2.501429    -2.685714    -2.627143     10.460000  ...    4.125714   \n",
       "...            ...          ...          ...           ...  ...         ...   \n",
       "2759898  -3.541429    -9.130000    -9.007143      0.507143  ...    6.231429   \n",
       "2759899  -8.072857   -12.847143   -12.498571     -3.115714  ...    4.784286   \n",
       "2759900 -10.298571   -14.704286   -14.268571     -4.091429  ...    4.600000   \n",
       "2759901  -5.717143    -9.964286    -9.821429      0.598571  ...    6.905714   \n",
       "2759902  -7.315000   -12.325000   -12.048333     -0.335000  ...    6.828333   \n",
       "\n",
       "         WS50M_MAX_mean  WS50M_MIN_mean  WS50M_RANGE_mean  score_max_0  \\\n",
       "0              6.934286        2.815714          4.120000          0.0   \n",
       "1              7.162857        2.968571          4.192857          0.0   \n",
       "2              6.682857        2.997143          3.685714          0.0   \n",
       "3              6.727143        3.244286          3.480000          0.0   \n",
       "4              5.971429        2.045714          3.927143          0.0   \n",
       "...                 ...             ...               ...          ...   \n",
       "2759898        8.827143        3.687143          5.140000          1.0   \n",
       "2759899        7.161429        2.328571          4.831429          1.0   \n",
       "2759900        7.524286        1.565714          5.957143          1.0   \n",
       "2759901        9.538571        4.108571          5.428571          1.0   \n",
       "2759902        9.515000        4.071667          5.443333          1.0   \n",
       "\n",
       "         score_max_1  score_max_2  score_max_3  score_max_4  score_max_5  \n",
       "0                1.0          0.0          0.0          0.0          0.0  \n",
       "1                0.0          1.0          0.0          0.0          0.0  \n",
       "2                0.0          1.0          0.0          0.0          0.0  \n",
       "3                0.0          1.0          0.0          0.0          0.0  \n",
       "4                1.0          0.0          0.0          0.0          0.0  \n",
       "...              ...          ...          ...          ...          ...  \n",
       "2759898          0.0          0.0          0.0          0.0          0.0  \n",
       "2759899          0.0          0.0          0.0          0.0          0.0  \n",
       "2759900          0.0          0.0          0.0          0.0          0.0  \n",
       "2759901          0.0          0.0          0.0          0.0          0.0  \n",
       "2759902          0.0          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[2756796 rows x 27 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_data.copy()\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(df[['score_max']])\n",
    "scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "ohed = df.drop(columns=['score_max'])\n",
    "ohed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6742ffd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.194828</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>-0.155185</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.125862</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>-0.118202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.270690</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.375635</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.257328</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>-0.480058</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.485345</td>\n",
       "      <td>-0.556951</td>\n",
       "      <td>-0.253082</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756791</th>\n",
       "      <td>0.376293</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.362582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756792</th>\n",
       "      <td>-0.126293</td>\n",
       "      <td>-0.391122</td>\n",
       "      <td>0.205946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756793</th>\n",
       "      <td>-0.016810</td>\n",
       "      <td>-0.838358</td>\n",
       "      <td>0.777375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756794</th>\n",
       "      <td>0.590948</td>\n",
       "      <td>0.652429</td>\n",
       "      <td>0.509065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756795</th>\n",
       "      <td>0.583836</td>\n",
       "      <td>0.630793</td>\n",
       "      <td>0.516558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756796 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               15        16        17   18   19   20   21   22   23   24   25  \\\n",
       "0       -0.194828 -0.105528 -0.155185 -1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1       -0.125862 -0.015913 -0.118202 -1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2       -0.270690  0.000838 -0.375635 -1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3       -0.257328  0.145729 -0.480058 -1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4       -0.485345 -0.556951 -0.253082 -1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "...           ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2756791  0.376293  0.405360  0.362582  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2756792 -0.126293 -0.391122  0.205946  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2756793 -0.016810 -0.838358  0.777375  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2756794  0.590948  0.652429  0.509065  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2756795  0.583836  0.630793  0.516558  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "          26   27   28   29       30      31    32  \n",
       "0        0.0  0.0  0.0  0.0   1001.0  2000.0   1.0  \n",
       "1        1.0  0.0  0.0  0.0   1001.0  2000.0   2.0  \n",
       "2        1.0  0.0  0.0  0.0   1001.0  2000.0   3.0  \n",
       "3        1.0  0.0  0.0  0.0   1001.0  2000.0   4.0  \n",
       "4        0.0  0.0  0.0  0.0   1001.0  2000.0   5.0  \n",
       "...      ...  ...  ...  ...      ...     ...   ...  \n",
       "2756791  0.0  0.0  0.0  0.0  56043.0  2016.0  48.0  \n",
       "2756792  0.0  0.0  0.0  0.0  56043.0  2016.0  49.0  \n",
       "2756793  0.0  0.0  0.0  0.0  56043.0  2016.0  50.0  \n",
       "2756794  0.0  0.0  0.0  0.0  56043.0  2016.0  51.0  \n",
       "2756795  0.0  0.0  0.0  0.0  56043.0  2016.0  52.0  \n",
       "\n",
       "[2756796 rows x 18 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.loc[::,15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d112f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1001.,  1003.,  1005., ..., 56039., 56041., 56043.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(preprocessed_data)[30].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ccd1d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2756796, 33), indices imply (2756796, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p9/9fqg02b5193fw889mjw1vkrw0000gn/T/ipykernel_5790/3949751728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#windowed_data = WindowGenerator(preprocessed_data,input_width=6,label_width=6,shift=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m#label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 )\n\u001b[1;32m    671\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    673\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/droughts/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (2756796, 33), indices imply (2756796, 28)"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(preprocessed_data,columns=df.columns)\n",
    "#windowed_data = WindowGenerator(preprocessed_data,input_width=6,label_width=6,shift=1,\n",
    "        #label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6551b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97eac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearning:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        #self.data = DataFunctions().light_weekly_aggregate()\n",
    "        self.features = self.data.drop(columns=['fips_','year','week_num_','score_max']).columns\n",
    "        \n",
    "    def robust(self):\n",
    "        df = self.data.copy()\n",
    "        for f in self.features:\n",
    "            median = np.median(df[f])\n",
    "            IQR = np.subtract(*np.percentile(df[f], [75, 25]))\n",
    "            df[f] = df[f].map(lambda x: (x-median)/IQR)\n",
    "        \n",
    "        self.scaled_data = df\n",
    "            \n",
    "    def preprocess(self):\n",
    "        self.robust()\n",
    "        self.preprocessed_data = WindowGenerator(self.scaled_data,input_width=6, label_width=1, shift=1,label_columns=['score_max']).make_dataset()\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        self.model = models.Sequential()\n",
    "        self.model.add(layers.LSTM(20))\n",
    "        self.model.add(layers.Dense(1,activation='sigmoid'))\n",
    "        self.model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    \n",
    "    def train_model(self):\n",
    "        self.initialize_model()\n",
    "        self.preprocess()\n",
    "        self.model.fit(self.preprocessed_data,epochs=1,batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ea1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_data = robust(train_data)[:int((len(train_data)*0.1))]\n",
    "scaled_val_data = robust(val_data)[:int((len(train_data)*0.1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd6141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ohe train\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "train_ohe = OneHotEncoder(sparse = False)\n",
    "train_ohe.fit(scaled_train_data[['score_max']])\n",
    "scoremax_encoded = train_ohe.transform(scaled_train_data[['score_max']])\n",
    "scaled_train_data[\"score_max_0\"],scaled_train_data[\"score_max_1\"],scaled_train_data['score_max_2'],scaled_train_data['score_max_3'],scaled_train_data['score_max_4'],scaled_train_data['score_max_5'] = scoremax_encoded.T \n",
    "scaled_train_data_ohe = scaled_train_data.drop(columns=['score_max'])\n",
    "\n",
    "#ohe val\n",
    "val_ohe = OneHotEncoder(sparse = False)\n",
    "val_ohe.fit(scaled_val_data[['score_max']])\n",
    "scoremax_encoded = val_ohe.transform(scaled_val_data[['score_max']])\n",
    "scaled_val_data[\"score_max_0\"],scaled_val_data[\"score_max_1\"],scaled_val_data['score_max_2'],scaled_val_data['score_max_3'],scaled_val_data['score_max_4'],scaled_val_data['score_max_5'] = scoremax_encoded.T \n",
    "scaled_val_data_ohe = scaled_val_data.drop(columns=['score_max'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.Dense(20,activation='relu'))\n",
    "    model.add(layers.Dense(6,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "def train_model(train_data,validation_data):\n",
    "    model = initialize_model()\n",
    "    history = model.fit(train_data,validation_data=validation_data,epochs=1000,batch_size=32,callbacks=EarlyStopping(patience=10,restore_best_weights=True),verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d24842",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_scaled_ohe = WindowGenerator(scaled_train_data_ohe,input_width=6,label_width=6,shift=1,label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\n",
    "preprocessed_scaled_ohe.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d91af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = train_model(preprocessed_train_ohe,preprocessed_val_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f492f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#predicted_classes = model.predict(X_test > 0.5).astype(\"int32\")[:, 0]\n",
    "#print(f'test recall score = {recall_score(y_test,predicted_classes)}')\n",
    "fig, ax = plt.subplots(1,2,figsize=(13,5))\n",
    "ax[0].plot(hist.history['loss'],label='train_loss')\n",
    "ax[0].plot(hist.history['val_loss'],label='val_loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(hist.history['accuracy'],label='train_accuracy')\n",
    "ax[1].plot(hist.history['val_accuracy'],label='val_accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21dc96a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_train_data_ohe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p9/9fqg02b5193fw889mjw1vkrw0000gn/T/ipykernel_5790/1010953150.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mwindow_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'window'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mwindower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'window'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscaled_train_data_ohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mkeras_wrapper_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialize_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaled_train_data_ohe' is not defined"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "\n",
    "class Window(): \n",
    "    \n",
    "    def fit(self,data):\n",
    "        self.data = data\n",
    "        self.window = WindowGenerator(self.data,input_width=6,label_width=6,shift=1,label_columns=['score_max_0','score_max_1','score_max_2','score_max_3','score_max_4','score_max_5'])\n",
    "        return self\n",
    " \n",
    "    def transform(self,data):\n",
    "        data_windowed = self.window.make_dataset()\n",
    "        return data_windowed\n",
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "    model.add(layers.Dense(20,activation='relu'))\n",
    "    model.add(layers.Dense(6,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "scaling_pipe = Pipeline([('robust_scaler',RobustScaler())])\n",
    "encoder = Pipeline([('ohe',OneHotEncoder())])\n",
    "preprocessor = ColumnTransformer([('scaling',scaling_pipe,train_data.drop(columns=['fips_','year_','week_num_','score_max']).columns),('cat_encoder',encoder,['score_max'])],remainder='passthrough')\n",
    "\n",
    "window_generator = Pipeline([('window',Window())])\n",
    "windower = ColumnTransformer([('window',window_generator,[col for col in scaled_train_data_ohe.columns])])\n",
    "\n",
    "keras_wrapper_model = KerasClassifier(build_fn=initialize_model,epochs=1,batch_size=32,callbacks=EarlyStopping(patience=10,restore_best_weights=True),verbose=1)\n",
    "\n",
    "final_pipe = Pipeline([('preprocessing', preprocessor),('window_generator',windower),('KerasClassifier', keras_wrapper_model)])\n",
    "final_pipe_trained = final_pipe.fit(train_data)\n",
    "final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed41849c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a61774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "\n",
    "from tensorflow.keras import models,layers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from droughts_modelling.data import DataFunctions\n",
    "from droughts_modelling.window_gen import WindowGenerator\n",
    "import numpy as np\n",
    "\n",
    "class DeepLearning2():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_data = DataFunctions().light_weekly_aggregate_train()\n",
    "        self.test_data = DataFunctions().light_weekly_aggregate_test()\n",
    "        self.features = self.data.drop(columns=['fips_','year_','week_num_','score_max']).columns\n",
    "    \n",
    "    #Train data preprocessing\n",
    "    def train_robust(self):\n",
    "        df = self.train_data.copy()\n",
    "        for f in self.features:\n",
    "            self.train_median = np.median(df[f])\n",
    "            self.train_iqr = np.subtract(*np.percentile(df[f], [75, 25]))\n",
    "            df[f] = df[f].map(lambda x: (x-self.train_median)/self.train_iqr)\n",
    "            \n",
    "        self.train_scaled_data = df\n",
    "        \n",
    "    def train_ohe(self):\n",
    "        self.train_robust()\n",
    "        df = self.train_scaled_data.copy()\n",
    "        ohe = OneHotEncoder(sparse = False)\n",
    "        ohe.fit(df[['score_max']])\n",
    "        scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "        df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "        self.scaled_train_data_ohe = df.drop(columns=['score_max'])\n",
    "        \n",
    "    def train_window(self):\n",
    "        self.train_ohe()\n",
    "        self.train_windowed_data = WindowGenerator(self.scaled_train_data_ohe,input_width=6,label_width=6,shift=1,label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\n",
    "    \n",
    "    #Test data preprocessing\n",
    "    def test_robust(self):\n",
    "        df = self.test_data.copy()\n",
    "        for f in self.features:\n",
    "            self.train_median = np.median(df[f])\n",
    "            self.train_iqr = np.subtract(*np.percentile(df[f], [75, 25]))\n",
    "            df[f] = df[f].map(lambda x: (x-self.train_median)/self.train_iqr)\n",
    "        \n",
    "        self.test_scaled_data = df\n",
    "    \n",
    "    def test_ohe(self):\n",
    "        self.test_robust()\n",
    "        df = self.test_scaled_data.copy()\n",
    "        ohe = OneHotEncoder(sparse = False)\n",
    "        ohe.fit(df[['score_max']])\n",
    "        scoremax_encoded = ohe.transform(df[['score_max']])\n",
    "        df[\"score_max_0\"],df[\"score_max_1\"],df['score_max_2'],df['score_max_3'],df['score_max_4'],df['score_max_5'] = scoremax_encoded.T \n",
    "        self.scaled_test_data_ohe = df.drop(columns=['score_max']) \n",
    "    \n",
    "    def test_window(self):\n",
    "        self.test_ohe()\n",
    "        self.test_windowed_data = WindowGenerator(self.scaled_test_data_ohe,input_width=6,label_width=6,shift=1,label_columns=[\"score_max_0\",\"score_max_1\",\"score_max_2\",\"score_max_3\",\"score_max_4\",\"score_max_5\"]).make_dataset()\n",
    "    \n",
    "    #Model + evaluation\n",
    "    def initialize_model(self):\n",
    "        self.model = models.Sequential()\n",
    "        self.model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "        self.model.add(layers.LSTM(32,return_sequences=True,activation='tanh'))\n",
    "        self.model.add(layers.Dense(20,activation='relu'))\n",
    "        self.model.add(layers.Dense(6,activation='softmax'))\n",
    "        self.model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "        \n",
    "    def train_model(self):\n",
    "        self.initialize_model()\n",
    "        self.train_window()\n",
    "        self.model.fit(self.train_windowed_data,epochs=1000,batch_size=32,verbose=1)\n",
    "        \n",
    "    def evaluate_model(self):\n",
    "        self.train_model()\n",
    "        self.test_window()\n",
    "        self.model.evauluate(self.test_windowed_data,verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e4ffc",
   "metadata": {},
   "source": [
    "### Manual coding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subsample_sequence(df, length):\n",
    "    df_sample = df.sample(length)\n",
    "    X_sample = df_sample.iloc[:-1].copy()\n",
    "    y_sample = float(df_sample[['score_max']].iloc[-1])\n",
    "    \n",
    "    return X_sample, y_sample\n",
    "\n",
    "def get_X_y(df, n_sequences, length):\n",
    "    X = [split_subsample_sequence(df, length)[0] for n in range(n_sequences)]\n",
    "    y = [split_subsample_sequence(df, length)[1] for n in range(n_sequences)]\n",
    "    \n",
    "    \n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5417a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df984cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_X_y(d, 2000, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ab5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subsample_sequence(df, length):\n",
    "    df_sample = df.sample(length,random_state=1)\n",
    "    X_sample = df_sample.iloc[:-1].copy()\n",
    "    y_sample = float(df_sample[['score_max']].iloc[-1])\n",
    "    \n",
    "    return X_sample, y_sample\n",
    "\n",
    "def get_X_y(df, n_sequences,length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for n in range(n_sequences):\n",
    "        sequence = split_subsample_sequence(df, length)\n",
    "        X.append(sequence[0])\n",
    "        y.append(sequence[1])\n",
    "    \n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def get_X_y_by_geolocation(df, n_sequences, length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for fip in sorted(set(df['fips_'])):\n",
    "        fip_df = df[df['fips_'] == fip]\n",
    "        sequences = get_X_y(fip_df,n_sequences,length)\n",
    "        X.append(sequences[0])\n",
    "        y.append(sequences[1])\n",
    "        \n",
    "\n",
    "    return np.array(X),np.array(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droughts",
   "language": "python",
   "name": "droughts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
